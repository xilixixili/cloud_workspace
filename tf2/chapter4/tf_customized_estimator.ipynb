{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 1.15.0\n",
      "tensorflow.python.keras.api._v1.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "train_file=\"./../chapter3/data/train.csv\"\n",
    "eval_file=\"./../chapter3/data/eval.csv\"\n",
    "\n",
    "train_df=pd.read_csv(train_file)\n",
    "eval_df=pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train=train_df.pop('survived')\n",
    "y_eval=eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns=['sex','n_siblings_spouses','parch','class','deck','embark_town','alone']\n",
    "numeric_columns=['age','fare']\n",
    "\n",
    "feature_columns=[]\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab=train_df[categorical_column].unique()\n",
    "    print(categorical_column,vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(categorical_column,vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df,label_df,epochs=10,shuffle=True,bs=32):\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset=dataset.shuffle(10000)\n",
    "    dataset=dataset.repeat(epochs).batch(bs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd342fc0b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.63792586, step = 1\n",
      "INFO:tensorflow:global_step/sec: 429.199\n",
      "INFO:tensorflow:loss = 0.49442452, step = 101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.028\n",
      "INFO:tensorflow:loss = 0.47202122, step = 201 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.741\n",
      "INFO:tensorflow:loss = 0.28837448, step = 301 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.874\n",
      "INFO:tensorflow:loss = 1.3062682, step = 401 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.475\n",
      "INFO:tensorflow:loss = 0.9470098, step = 501 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.013\n",
      "INFO:tensorflow:loss = 0.71323, step = 601 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.022\n",
      "INFO:tensorflow:loss = 0.42804766, step = 701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.966\n",
      "INFO:tensorflow:loss = 0.27828085, step = 801 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.907\n",
      "INFO:tensorflow:loss = 0.30163658, step = 901 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.276\n",
      "INFO:tensorflow:loss = 0.49258423, step = 1001 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.198\n",
      "INFO:tensorflow:loss = 0.4919696, step = 1101 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.395\n",
      "INFO:tensorflow:loss = 0.36417142, step = 1201 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.091\n",
      "INFO:tensorflow:loss = 0.47803307, step = 1301 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.691\n",
      "INFO:tensorflow:loss = 0.34324437, step = 1401 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.915\n",
      "INFO:tensorflow:loss = 0.439474, step = 1501 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.534\n",
      "INFO:tensorflow:loss = 0.51763, step = 1601 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.774\n",
      "INFO:tensorflow:loss = 0.43471023, step = 1701 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.649\n",
      "INFO:tensorflow:loss = 0.4323185, step = 1801 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.625\n",
      "INFO:tensorflow:loss = 0.37411916, step = 1901 (0.148 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.889375.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fd3430d2f60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir=\"customized_estimator\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    # model tuntime state:Train,Eval, Predict\n",
    "    input_for_next_layer=tf.feature_column.input_layer(features,params['feature_columns'])\n",
    "    for n_unit in params['hidden_units']:\n",
    "        input_for_next_layer=tf.layers.dense(input_for_next_layer,units=n_unit,activation=tf.nn.relu)\n",
    "    logits=tf.layers.dense(input_for_next_layer,params['n_classes'],activation=None)\n",
    "    \n",
    "    predicted_classes=tf.argmax(logits,1)\n",
    "    \n",
    "    if mode==tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions={\n",
    "            \"class_ids\":predicted_classes[:,tf.newaxis],\n",
    "            \"prebabilities\":tf.nn.softmax(logits),\n",
    "            \"logits\":logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
    "    loss= tf.losses.sparse_softmax_cross_entropy(labels= labels,logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(labels= labels, predictions=predicted_classes,name=\"acc_op\")\n",
    "    metrics={\"accuracy\":accuracy}\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode,loss=loss,eval_metric_ops= metrics)\n",
    "    optimizer= tf.train.AdamOptimizer()\n",
    "    train_op= optimizer.minimize(loss,global_step=tf.train.get_global_step())\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\n",
    "\n",
    "estimator= tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=output_dir,\n",
    "    params={\n",
    "        \"feature_columns\": feature_columns,\n",
    "        \"hidden_units\":[100,100],\n",
    "        \"n_classes\": 2})\n",
    "estimator.train(input_fn=lambda: make_dataset(train_df,y_train,epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-12T16:02:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-12-16:02:40\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.8030303, global_step = 1960, loss = 0.47353923\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8030303, 'loss': 0.47353923, 'global_step': 1960}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(lambda:make_dataset(eval_df,y_eval,epochs=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
