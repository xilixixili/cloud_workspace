{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-keras 和 keras 区别\n",
    "- tf.kears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing=fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3870, 8) (3870,)\n",
      "(11610, 8) (11610,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all,x_test,y_train_all,y_test=train_test_split(housing.data,housing.target,random_state=7)\n",
    "x_train,x_valid,y_train,y_valid=train_test_split(x_train_all,y_train_all,random_state=11)\n",
    "\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "x_train_s=scaler.fit_transform(x_train)\n",
    "x_valid_s=scaler.fit_transform(x_valid)\n",
    "x_test_s=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 78us/sample - loss: 1.4405 - val_loss: 0.6978\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.6123 - val_loss: 0.6089\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5482 - val_loss: 0.5452\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5086 - val_loss: 0.5034\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.4820 - val_loss: 0.4834\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4646 - val_loss: 0.4576\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4561 - val_loss: 0.4568\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4470 - val_loss: 0.4373\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4408 - val_loss: 0.4323\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4339 - val_loss: 0.4309\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4249 - val_loss: 0.4213\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4221 - val_loss: 0.4157\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4196 - val_loss: 0.4210\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4136 - val_loss: 0.4102\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.4097 - val_loss: 0.4059\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4083 - val_loss: 0.4032\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4044 - val_loss: 0.4080\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4006 - val_loss: 0.4023\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3984 - val_loss: 0.4013\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "#1. 转化为sklearn的model\n",
    "#2. 定义参数集合\n",
    "#3. 搜索参数\n",
    "\n",
    "def build_model(hidden_layers=1,layer_size=30,learning_rate=3e-3):\n",
    "    model=keras.models.Sequential([\n",
    "        keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "        \n",
    "    ])\n",
    "    for _ in range(hidden_layers-1):\n",
    "        model.add(keras.layers.Dense(layer_size,activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer=keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "    return model\n",
    "sklearn_model=keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]\n",
    "histroy=sklearn_model.fit(x_train_s,y_train,epochs=100,validation_data=(x_valid_s,y_valid),callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(histroy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 115us/sample - loss: 3.9618 - val_loss: 2.4807\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 1.6533 - val_loss: 1.3438\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 1.1349 - val_loss: 1.0838\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.9629 - val_loss: 0.9442\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.8549 - val_loss: 0.8549\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.7823 - val_loss: 0.7949\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.7338 - val_loss: 0.7552\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.6982 - val_loss: 0.7250\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.6709 - val_loss: 0.7004\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.6490 - val_loss: 0.6812\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.6305 - val_loss: 0.6635\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.6149 - val_loss: 0.6495\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.6016 - val_loss: 0.6376\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.5900 - val_loss: 0.6251\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5799 - val_loss: 0.6151\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5709 - val_loss: 0.6067\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5630 - val_loss: 0.5983\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5558 - val_loss: 0.5886\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5492 - val_loss: 0.5817\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.5432 - val_loss: 0.5759\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5376 - val_loss: 0.5700\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5323 - val_loss: 0.5629\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5275 - val_loss: 0.5570\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.5226 - val_loss: 0.5547\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.5185 - val_loss: 0.5479\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5144 - val_loss: 0.5433\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 0.5105 - val_loss: 0.5396\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.5066 - val_loss: 0.5362\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.5031 - val_loss: 0.5300\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.4995 - val_loss: 0.5271\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 1s 67us/sample - loss: 0.4960 - val_loss: 0.5248\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4930 - val_loss: 0.5188\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4897 - val_loss: 0.5202\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4870 - val_loss: 0.5117\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 0.4839 - val_loss: 0.5076\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4811 - val_loss: 0.5055\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4784 - val_loss: 0.5019\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4759 - val_loss: 0.5004\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4733 - val_loss: 0.4950\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4709 - val_loss: 0.4939\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 0.4686 - val_loss: 0.4904\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.4663 - val_loss: 0.4862\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 0.4643 - val_loss: 0.4867\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4621 - val_loss: 0.4843\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4602 - val_loss: 0.4813\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4582 - val_loss: 0.4785\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4562 - val_loss: 0.4772\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4544 - val_loss: 0.4742\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4527 - val_loss: 0.4732\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4507 - val_loss: 0.4733\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4494 - val_loss: 0.4685\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4476 - val_loss: 0.4651\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4462 - val_loss: 0.4634\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4447 - val_loss: 0.4629\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4432 - val_loss: 0.4599\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4418 - val_loss: 0.4588\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4403 - val_loss: 0.4591\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4390 - val_loss: 0.4550\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4022\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 84us/sample - loss: 4.5853 - val_loss: 3.6721\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 2.6124 - val_loss: 2.0190\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 1.4967 - val_loss: 1.3122\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 1.1214 - val_loss: 1.0703\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.9687 - val_loss: 0.9451\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.8693 - val_loss: 0.8599\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.8010 - val_loss: 0.8018\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.7525 - val_loss: 0.7618\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.7187 - val_loss: 0.7327\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6946 - val_loss: 0.7120\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6763 - val_loss: 0.6970\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6618 - val_loss: 0.6837\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6493 - val_loss: 0.6722\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.6382 - val_loss: 0.6630\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.6280 - val_loss: 0.6521\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6184 - val_loss: 0.6454\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.6094 - val_loss: 0.6345\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6006 - val_loss: 0.6257\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5922 - val_loss: 0.6170\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5842 - val_loss: 0.6104\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5766 - val_loss: 0.6004\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5692 - val_loss: 0.5929\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5620 - val_loss: 0.5849\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5552 - val_loss: 0.5778\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5487 - val_loss: 0.5711\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5425 - val_loss: 0.5651\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5362 - val_loss: 0.5566\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.5307 - val_loss: 0.5514\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5251 - val_loss: 0.5454\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5198 - val_loss: 0.5388\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5147 - val_loss: 0.5329\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5100 - val_loss: 0.5287\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5054 - val_loss: 0.5234\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5010 - val_loss: 0.5178\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4969 - val_loss: 0.5148\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4929 - val_loss: 0.5113\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4892 - val_loss: 0.5051\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4856 - val_loss: 0.5010\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4820 - val_loss: 0.4963\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4787 - val_loss: 0.4930\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4755 - val_loss: 0.4886\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4725 - val_loss: 0.4848\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4695 - val_loss: 0.4809\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4666 - val_loss: 0.4774\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4640 - val_loss: 0.4762\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4613 - val_loss: 0.4712\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4587 - val_loss: 0.4678\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4563 - val_loss: 0.4669\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4539 - val_loss: 0.4625\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4517 - val_loss: 0.4597\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4493 - val_loss: 0.4589\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4472 - val_loss: 0.4545\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4450 - val_loss: 0.4535\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4429 - val_loss: 0.4499\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4408 - val_loss: 0.4469\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4388 - val_loss: 0.4444\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4369 - val_loss: 0.4423\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4350 - val_loss: 0.4420\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4331 - val_loss: 0.4398\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4314 - val_loss: 0.4375\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4296 - val_loss: 0.4348\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4372\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 84us/sample - loss: 3.1793 - val_loss: 2.0656\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 1.6255 - val_loss: 1.3771\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 1.1569 - val_loss: 1.0571\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.9129 - val_loss: 0.8753\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.7703 - val_loss: 0.7677\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6912 - val_loss: 0.7094\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6487 - val_loss: 0.6775\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.6246 - val_loss: 0.6559\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6091 - val_loss: 0.6454\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5976 - val_loss: 0.6299\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5880 - val_loss: 0.6201\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5795 - val_loss: 0.6112\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5716 - val_loss: 0.6034\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5642 - val_loss: 0.5974\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5578 - val_loss: 0.5874\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5515 - val_loss: 0.5801\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5456 - val_loss: 0.5724\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5401 - val_loss: 0.5668\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5349 - val_loss: 0.5612\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5300 - val_loss: 0.5543\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5252 - val_loss: 0.5491\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5206 - val_loss: 0.5444\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5165 - val_loss: 0.5391\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5122 - val_loss: 0.5334\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5082 - val_loss: 0.5287\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5042 - val_loss: 0.5236\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5005 - val_loss: 0.5198\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4969 - val_loss: 0.5151\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4934 - val_loss: 0.5106\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4901 - val_loss: 0.5074\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4869 - val_loss: 0.5025\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4838 - val_loss: 0.4979\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4807 - val_loss: 0.4947\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4776 - val_loss: 0.4919\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4748 - val_loss: 0.4876\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4721 - val_loss: 0.4840\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4692 - val_loss: 0.4803\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4668 - val_loss: 0.4779\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.4643 - val_loss: 0.4748\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4619 - val_loss: 0.4709\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4595 - val_loss: 0.4681\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4572 - val_loss: 0.4651\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4550 - val_loss: 0.4630\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4528 - val_loss: 0.4590\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4505 - val_loss: 0.4587\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4485 - val_loss: 0.4530\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4465 - val_loss: 0.4522\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4444 - val_loss: 0.4509\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4426 - val_loss: 0.4462\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4407 - val_loss: 0.4441\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4389 - val_loss: 0.4414\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4371 - val_loss: 0.4406\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4353 - val_loss: 0.4371\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4335 - val_loss: 0.4346\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4318 - val_loss: 0.4350\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4301 - val_loss: 0.4304\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4289 - val_loss: 0.4299\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4271 - val_loss: 0.4295\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4258 - val_loss: 0.4256\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4252\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 84us/sample - loss: 3.5799 - val_loss: 2.2964\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 1.6707 - val_loss: 1.4688\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 1.2687 - val_loss: 1.2184\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 1.0672 - val_loss: 1.0483\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.9313 - val_loss: 0.9340\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.8407 - val_loss: 0.8586\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.7793 - val_loss: 0.8098\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.7406 - val_loss: 0.7804\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.7144 - val_loss: 0.7580\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6953 - val_loss: 0.7422\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6806 - val_loss: 0.7287\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6685 - val_loss: 0.7173\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6584 - val_loss: 0.7085\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.6496 - val_loss: 0.6997\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6416 - val_loss: 0.6939\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6348 - val_loss: 0.6856\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6281 - val_loss: 0.6806\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6220 - val_loss: 0.6738\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6162 - val_loss: 0.6681\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6108 - val_loss: 0.6621\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6055 - val_loss: 0.6567\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6003 - val_loss: 0.6508\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5955 - val_loss: 0.6463\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5907 - val_loss: 0.6403\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5862 - val_loss: 0.6355\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5818 - val_loss: 0.6315\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5773 - val_loss: 0.6260\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.5730 - val_loss: 0.6214\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5689 - val_loss: 0.6169\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5648 - val_loss: 0.6135\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5608 - val_loss: 0.6082\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5567 - val_loss: 0.6039\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5530 - val_loss: 0.5986\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.5490 - val_loss: 0.5936\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5455 - val_loss: 0.5904\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5418 - val_loss: 0.5872\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5383 - val_loss: 0.5816\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5346 - val_loss: 0.5770\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5311 - val_loss: 0.5723\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5279 - val_loss: 0.5687\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5244 - val_loss: 0.5647\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5210 - val_loss: 0.5618\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5177 - val_loss: 0.5564\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5145 - val_loss: 0.5526\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5111 - val_loss: 0.5520\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5083 - val_loss: 0.5469\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5051 - val_loss: 0.5423\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5020 - val_loss: 0.5392\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4991 - val_loss: 0.5354\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4958 - val_loss: 0.5294\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4931 - val_loss: 0.5283\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4903 - val_loss: 0.5228\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4874 - val_loss: 0.5201\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4845 - val_loss: 0.5151\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4819 - val_loss: 0.5116\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4792 - val_loss: 0.5081\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4765 - val_loss: 0.5053\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4736 - val_loss: 0.5011\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4712 - val_loss: 0.5004\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4685 - val_loss: 0.4947\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4664 - val_loss: 0.4926\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4638 - val_loss: 0.4910\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4614 - val_loss: 0.4880\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4590 - val_loss: 0.4858\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.4567 - val_loss: 0.4836\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4545 - val_loss: 0.4810\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4523 - val_loss: 0.4765\n",
      "Epoch 68/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4500 - val_loss: 0.4746\n",
      "Epoch 69/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4478 - val_loss: 0.4711\n",
      "Epoch 70/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4459 - val_loss: 0.4685\n",
      "Epoch 71/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4438 - val_loss: 0.4667\n",
      "Epoch 72/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4419 - val_loss: 0.4649\n",
      "Epoch 73/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4398 - val_loss: 0.4614\n",
      "Epoch 74/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4380 - val_loss: 0.4606\n",
      "Epoch 75/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4362 - val_loss: 0.4572\n",
      "Epoch 76/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4343 - val_loss: 0.4546\n",
      "Epoch 77/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4322 - val_loss: 0.4532\n",
      "Epoch 78/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4307 - val_loss: 0.4521\n",
      "Epoch 79/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4290 - val_loss: 0.4489\n",
      "Epoch 80/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4273 - val_loss: 0.4467\n",
      "Epoch 81/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4258 - val_loss: 0.4447\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4490\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 87us/sample - loss: 3.7553 - val_loss: 2.6315\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 1.9568 - val_loss: 1.7389\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 1.4704 - val_loss: 1.4064\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 1.2164 - val_loss: 1.1936\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 1.0394 - val_loss: 1.0448\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.9085 - val_loss: 0.9264\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.8126 - val_loss: 0.8461\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.7422 - val_loss: 0.7836\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6945 - val_loss: 0.7439\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6634 - val_loss: 0.7144\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6432 - val_loss: 0.6990\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6289 - val_loss: 0.6838\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.6180 - val_loss: 0.6702\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.6093 - val_loss: 0.6631\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6016 - val_loss: 0.6544\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5948 - val_loss: 0.6485\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5885 - val_loss: 0.6402\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5827 - val_loss: 0.6336\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5772 - val_loss: 0.6263\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5719 - val_loss: 0.6224\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5672 - val_loss: 0.6160\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5621 - val_loss: 0.6136\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5580 - val_loss: 0.6032\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5537 - val_loss: 0.6000\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5494 - val_loss: 0.5941\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5455 - val_loss: 0.5909\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 1s 58us/sample - loss: 0.5418 - val_loss: 0.5863\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5380 - val_loss: 0.5812\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5345 - val_loss: 0.5780\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5311 - val_loss: 0.5725\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5277 - val_loss: 0.5686\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5244 - val_loss: 0.5651\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5213 - val_loss: 0.5616\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5180 - val_loss: 0.5566\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5149 - val_loss: 0.5516\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5120 - val_loss: 0.5495\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5090 - val_loss: 0.5477\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5062 - val_loss: 0.5422\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5033 - val_loss: 0.5364\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5007 - val_loss: 0.5344\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4980 - val_loss: 0.5329\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4953 - val_loss: 0.5288\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4926 - val_loss: 0.5242\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.4900 - val_loss: 0.5239\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4875 - val_loss: 0.5184\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4850 - val_loss: 0.5179\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4827 - val_loss: 0.5136\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4801 - val_loss: 0.5109\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4776 - val_loss: 0.5056\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4755 - val_loss: 0.5054\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4734 - val_loss: 0.5011\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4712 - val_loss: 0.4979\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4689 - val_loss: 0.4931\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4669 - val_loss: 0.4925\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4648 - val_loss: 0.4900\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4627 - val_loss: 0.4894\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4606 - val_loss: 0.4873\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4588 - val_loss: 0.4823\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4566 - val_loss: 0.4786\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4548 - val_loss: 0.4772\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4529 - val_loss: 0.4739\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4510 - val_loss: 0.4722\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4493 - val_loss: 0.4686\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4476 - val_loss: 0.4682\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4457 - val_loss: 0.4645\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4438 - val_loss: 0.4612\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4423 - val_loss: 0.4627\n",
      "Epoch 68/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4407 - val_loss: 0.4607\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4714\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 1.1367 - val_loss: 0.7425\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6543 - val_loss: 0.6599\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5995 - val_loss: 0.6145\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5530 - val_loss: 0.5678\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5388 - val_loss: 0.5935\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5157 - val_loss: 0.5527\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5295 - val_loss: 0.5455\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4906 - val_loss: 0.5103\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4852 - val_loss: 0.5071\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4682 - val_loss: 0.4733\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4616 - val_loss: 0.4858\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4511 - val_loss: 0.4650\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4461 - val_loss: 0.4606\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4384 - val_loss: 0.4462\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4356 - val_loss: 0.4433\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4277 - val_loss: 0.4334\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4271 - val_loss: 0.4274\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4160 - val_loss: 0.4254\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4159 - val_loss: 0.4248\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4111 - val_loss: 0.4149\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4078 - val_loss: 0.4115\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4040 - val_loss: 0.4069\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4025 - val_loss: 0.4112\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3993 - val_loss: 0.4032\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3973 - val_loss: 0.3996\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3948 - val_loss: 0.4012\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3935 - val_loss: 0.4011\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3915 - val_loss: 0.3957\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3896 - val_loss: 0.3975\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.3652\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 95us/sample - loss: 1.3809 - val_loss: 0.8100\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6977 - val_loss: 0.6211\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5658 - val_loss: 0.5540\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5117 - val_loss: 0.5135\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4849 - val_loss: 0.4862\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4708 - val_loss: 0.4746\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4645 - val_loss: 0.4673\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4518 - val_loss: 0.4593\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4455 - val_loss: 0.4491\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4356 - val_loss: 0.4467\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4317 - val_loss: 0.4347\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4291 - val_loss: 0.4353\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4292 - val_loss: 0.4370\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4326 - val_loss: 0.4286\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4227 - val_loss: 0.4189\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4137 - val_loss: 0.4157\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4114 - val_loss: 0.4113\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4096 - val_loss: 0.4187\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4060 - val_loss: 0.4097\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4062 - val_loss: 0.4146\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.4139\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 1.2464 - val_loss: 0.7802\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6171 - val_loss: 0.5845\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5329 - val_loss: 0.5329\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4992 - val_loss: 0.5157\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4838 - val_loss: 0.4936\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4664 - val_loss: 0.4912\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4566 - val_loss: 0.4678\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4492 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4452 - val_loss: 0.4577\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4422 - val_loss: 0.4468\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4378 - val_loss: 0.4429\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4284 - val_loss: 0.4355\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4220 - val_loss: 0.4315\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4209 - val_loss: 0.4242\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4142 - val_loss: 0.4236\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4123 - val_loss: 0.4189\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4096 - val_loss: 0.4081\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4049 - val_loss: 0.4058\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4071 - val_loss: 0.4103\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4002 - val_loss: 0.4009\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3973 - val_loss: 0.4071\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3925 - val_loss: 0.4052\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.3918\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 67us/sample - loss: 1.1150 - val_loss: 0.9643\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9031 - val_loss: 1.2120\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 1.0471 - val_loss: 0.6054\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5483 - val_loss: 0.5542\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5099 - val_loss: 0.5221\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4856 - val_loss: 0.4962\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4674 - val_loss: 0.4778\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4556 - val_loss: 0.4653\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4462 - val_loss: 0.4564\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4390 - val_loss: 0.4489\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4322 - val_loss: 0.4383\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4275 - val_loss: 0.4342\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4225 - val_loss: 0.4278\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4184 - val_loss: 0.4252\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4142 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4101 - val_loss: 0.4191\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4074 - val_loss: 0.4151\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4039 - val_loss: 0.4112\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4012 - val_loss: 0.4103\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3981 - val_loss: 0.4064\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3953 - val_loss: 0.4057\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3938 - val_loss: 0.4021\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3917 - val_loss: 0.4027\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3894 - val_loss: 0.3984\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3874 - val_loss: 0.3961\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3851 - val_loss: 0.3970\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3843 - val_loss: 0.3968\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4062\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 1.3634 - val_loss: 0.7355\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6257 - val_loss: 0.6338\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5628 - val_loss: 0.5814\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5268 - val_loss: 0.5841\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5585 - val_loss: 0.6342\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6348 - val_loss: 0.5097\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4762 - val_loss: 0.4963\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4653 - val_loss: 0.4897\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4556 - val_loss: 0.4734\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4483 - val_loss: 0.4645\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.4435 - val_loss: 0.4556\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4393 - val_loss: 0.4478\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4322 - val_loss: 0.4460\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4277 - val_loss: 0.4431\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4239 - val_loss: 0.4296\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4197 - val_loss: 0.4296\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4159 - val_loss: 0.4246\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4166 - val_loss: 0.4259\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4097 - val_loss: 0.4182\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4060 - val_loss: 0.4154\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4019 - val_loss: 0.4086\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3977 - val_loss: 0.4181\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3971 - val_loss: 0.4053\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3927 - val_loss: 0.4110\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.3914 - val_loss: 0.4049\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3875 - val_loss: 0.4103\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.3893 - val_loss: 0.4056\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.3847 - val_loss: 0.4101\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.4058\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 2.0342 - val_loss: 0.8413\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7028 - val_loss: 0.7066\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6375 - val_loss: 0.6688\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6014 - val_loss: 0.6319\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5758 - val_loss: 0.6079\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5567 - val_loss: 0.5886\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5385 - val_loss: 0.5661\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5267 - val_loss: 0.5548\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5161 - val_loss: 0.5434\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5062 - val_loss: 0.5392\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5001 - val_loss: 0.5273\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4939 - val_loss: 0.5173\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4874 - val_loss: 0.5083\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4822 - val_loss: 0.5052\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4806 - val_loss: 0.4997\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4738 - val_loss: 0.4901\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4723 - val_loss: 0.4887\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4674 - val_loss: 0.4816\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4646 - val_loss: 0.4792\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4621 - val_loss: 0.4777\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4582 - val_loss: 0.4717\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4570 - val_loss: 0.4698\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4542 - val_loss: 0.4683\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4505 - val_loss: 0.4673\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.4516 - val_loss: 0.4645\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4479 - val_loss: 0.4586\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4448 - val_loss: 0.4510\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4422 - val_loss: 0.4487\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4407 - val_loss: 0.4465\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4377 - val_loss: 0.4406\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4375 - val_loss: 0.4433\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4345 - val_loss: 0.4415\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4326 - val_loss: 0.4353\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4303 - val_loss: 0.4331\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4297 - val_loss: 0.4303\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4266 - val_loss: 0.4299\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4247 - val_loss: 0.4253\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4239 - val_loss: 0.4271\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4212 - val_loss: 0.4229\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4202 - val_loss: 0.4201\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4182 - val_loss: 0.4166\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4167 - val_loss: 0.4161\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4149 - val_loss: 0.4127\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4134 - val_loss: 0.4156\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4119 - val_loss: 0.4104\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3817\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 1.4103 - val_loss: 0.7756\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6705 - val_loss: 0.6851\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6161 - val_loss: 0.6424\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5805 - val_loss: 0.6061\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5523 - val_loss: 0.5758\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5294 - val_loss: 0.5555\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5110 - val_loss: 0.5369\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4984 - val_loss: 0.5234\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4874 - val_loss: 0.5154\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4778 - val_loss: 0.4999\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4716 - val_loss: 0.4938\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4660 - val_loss: 0.4853\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4600 - val_loss: 0.4838\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4537 - val_loss: 0.4798\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4519 - val_loss: 0.4726\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4472 - val_loss: 0.4643\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4456 - val_loss: 0.4632\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4412 - val_loss: 0.4564\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4374 - val_loss: 0.4544\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4347 - val_loss: 0.4481\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4321 - val_loss: 0.4468\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4318 - val_loss: 0.4455\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4301 - val_loss: 0.4402\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4271 - val_loss: 0.4397\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4246 - val_loss: 0.4347\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4224 - val_loss: 0.4321\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4198 - val_loss: 0.4262\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4183 - val_loss: 0.4280\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4155 - val_loss: 0.4253\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4147 - val_loss: 0.4219\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4137 - val_loss: 0.4213\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4112 - val_loss: 0.4189\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4103 - val_loss: 0.4176\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4093 - val_loss: 0.4152\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4076 - val_loss: 0.4149\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.4205\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 1.6470 - val_loss: 0.8368\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6971 - val_loss: 0.6865\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6148 - val_loss: 0.6304\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5682 - val_loss: 0.5819\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5380 - val_loss: 0.5516\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5173 - val_loss: 0.5307\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.5022 - val_loss: 0.5135\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4942 - val_loss: 0.5051\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4812 - val_loss: 0.4938\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4742 - val_loss: 0.4862\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4677 - val_loss: 0.4782\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4638 - val_loss: 0.4706\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4579 - val_loss: 0.4677\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4533 - val_loss: 0.4785\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4513 - val_loss: 0.4662\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4441 - val_loss: 0.4468\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4419 - val_loss: 0.4479\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4399 - val_loss: 0.4472\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4348 - val_loss: 0.4359\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4334 - val_loss: 0.4407\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4295 - val_loss: 0.4338\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4282 - val_loss: 0.4329\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4247 - val_loss: 0.4265\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4239 - val_loss: 0.4248\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4196 - val_loss: 0.4206\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4168 - val_loss: 0.4174\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4157 - val_loss: 0.4151\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4134 - val_loss: 0.4135\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4107 - val_loss: 0.4181\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4096 - val_loss: 0.4127\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4074 - val_loss: 0.4080\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4050 - val_loss: 0.4109\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4029 - val_loss: 0.4047\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.4060\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 2.3341 - val_loss: 1.0638\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.8261 - val_loss: 0.7738\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7065 - val_loss: 0.7139\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6542 - val_loss: 0.6650\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6158 - val_loss: 0.6299\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5849 - val_loss: 0.6011\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5585 - val_loss: 0.5756\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5383 - val_loss: 0.5531\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.5197 - val_loss: 0.5349\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5059 - val_loss: 0.5189\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4934 - val_loss: 0.5053\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4833 - val_loss: 0.4958\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4744 - val_loss: 0.4874\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4674 - val_loss: 0.4760\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4606 - val_loss: 0.4718\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4555 - val_loss: 0.4655\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4501 - val_loss: 0.4593\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4454 - val_loss: 0.4538\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4415 - val_loss: 0.4507\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4376 - val_loss: 0.4472\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4337 - val_loss: 0.4460\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4312 - val_loss: 0.4397\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4279 - val_loss: 0.4368\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4252 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4228 - val_loss: 0.4320\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4206 - val_loss: 0.4295\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4186 - val_loss: 0.4286\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4166 - val_loss: 0.4274\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4149 - val_loss: 0.4244\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4134 - val_loss: 0.4293\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4119 - val_loss: 0.4233\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.4286\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 2.0071 - val_loss: 0.8985\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7145 - val_loss: 0.7308\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6547 - val_loss: 0.6854\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6187 - val_loss: 0.6451\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5893 - val_loss: 0.6149\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5656 - val_loss: 0.5943\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5449 - val_loss: 0.5736\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5283 - val_loss: 0.5523\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5140 - val_loss: 0.5377\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5023 - val_loss: 0.5241\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4916 - val_loss: 0.5110\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4834 - val_loss: 0.5016\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4757 - val_loss: 0.4915\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4689 - val_loss: 0.4853\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4634 - val_loss: 0.4740\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4583 - val_loss: 0.4678\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4535 - val_loss: 0.4615\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4494 - val_loss: 0.4583\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4452 - val_loss: 0.4564\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4420 - val_loss: 0.4461\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4386 - val_loss: 0.4453\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4353 - val_loss: 0.4409\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4324 - val_loss: 0.4372\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4298 - val_loss: 0.4342\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4269 - val_loss: 0.4299\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4244 - val_loss: 0.4292\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4218 - val_loss: 0.4236\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4199 - val_loss: 0.4245\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4179 - val_loss: 0.4230\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4163 - val_loss: 0.4171\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4138 - val_loss: 0.4150\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4122 - val_loss: 0.4136\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4343\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 83us/sample - loss: 0.7868 - val_loss: 0.5241\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4818 - val_loss: 0.4433\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4225 - val_loss: 0.4042\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4025 - val_loss: 0.3870\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3875 - val_loss: 0.3747\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3762 - val_loss: 0.3691\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3689 - val_loss: 0.3748\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3618 - val_loss: 0.3697\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3552 - val_loss: 0.3676\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3517 - val_loss: 0.3744\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3414\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 79us/sample - loss: 0.9676 - val_loss: 0.5845\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5156 - val_loss: 0.4916\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4514 - val_loss: 0.4377\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4174 - val_loss: 0.4082\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3963 - val_loss: 0.4553\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3831 - val_loss: 0.3850\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3761 - val_loss: 0.3805\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3691 - val_loss: 0.3840\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3619 - val_loss: 0.3922\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3581 - val_loss: 0.3795\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3509 - val_loss: 0.3729\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3490 - val_loss: 0.3754\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3465 - val_loss: 0.4183\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3403 - val_loss: 0.3688\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3377 - val_loss: 0.3658\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3328 - val_loss: 0.4044\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3845\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 79us/sample - loss: 1.3412 - val_loss: 0.5325\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4750 - val_loss: 0.4537\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4323 - val_loss: 0.4242\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4025 - val_loss: 0.3928\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3883 - val_loss: 0.4045\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3803 - val_loss: 0.3853\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3677 - val_loss: 0.4438\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3554 - val_loss: 0.3883\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3521 - val_loss: 0.3644\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3444 - val_loss: 0.3633\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.3414 - val_loss: 0.3606\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3336 - val_loss: 0.3871\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3312 - val_loss: 0.4850\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3276 - val_loss: 0.3666\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.3291\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 106us/sample - loss: 1.0290 - val_loss: 1.0727\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.9451 - val_loss: 1.0222\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.9608 - val_loss: 0.5329\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4728 - val_loss: 0.4545\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4255 - val_loss: 0.4053\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3971 - val_loss: 0.3934\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3801 - val_loss: 0.3844\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3696 - val_loss: 0.3758\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3614 - val_loss: 0.3940\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3552 - val_loss: 0.3750\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3492 - val_loss: 0.3798\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3424 - val_loss: 0.3793\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3394 - val_loss: 0.4271\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4344\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 82us/sample - loss: 0.9576 - val_loss: 0.5667\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4848 - val_loss: 0.4749\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4293 - val_loss: 0.4355\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4016 - val_loss: 0.4125\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3897 - val_loss: 0.4366\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3938 - val_loss: 0.3914\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3684 - val_loss: 0.3836\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3645 - val_loss: 0.3802\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3588 - val_loss: 0.3844\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3495 - val_loss: 0.3728\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3447 - val_loss: 0.3845\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3409 - val_loss: 0.3718\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3398 - val_loss: 0.3728\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3646\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 73us/sample - loss: 1.2004 - val_loss: 0.8760\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6952 - val_loss: 0.6271\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5748 - val_loss: 0.5593\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5240 - val_loss: 0.5298\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4975 - val_loss: 0.5055\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4822 - val_loss: 0.4712\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4642 - val_loss: 0.4544\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4506 - val_loss: 0.4371\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4465 - val_loss: 0.4345\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4299 - val_loss: 0.4165\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4242 - val_loss: 0.4056\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4149 - val_loss: 0.4008\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.4144 - val_loss: 0.3968\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4035 - val_loss: 0.3920\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4017 - val_loss: 0.3876\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3928 - val_loss: 0.3831\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3936 - val_loss: 0.3893\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3857 - val_loss: 0.3781\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.3862 - val_loss: 0.3866\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3786 - val_loss: 0.3782\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.3889 - val_loss: 0.4064\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.3754 - val_loss: 0.3798\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.3723 - val_loss: 0.4717\n",
      "2322/2322 [==============================] - 0s 30us/sample - loss: 0.3852\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 96us/sample - loss: 1.4021 - val_loss: 0.6648\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.5844 - val_loss: 0.5898\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.5262 - val_loss: 0.5299\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4913 - val_loss: 0.5019\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4702 - val_loss: 0.4768\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4538 - val_loss: 0.4620\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.4417 - val_loss: 0.4510\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4337 - val_loss: 0.4506\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.4254 - val_loss: 0.4284\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 63us/sample - loss: 0.4187 - val_loss: 0.4218\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 1s 58us/sample - loss: 0.4119 - val_loss: 0.4166\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4057 - val_loss: 0.4203\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4013 - val_loss: 0.4122\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3970 - val_loss: 0.4013\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3924 - val_loss: 0.3974\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3898 - val_loss: 0.3904\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3862 - val_loss: 0.3876\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 1s 67us/sample - loss: 0.3834 - val_loss: 0.3883\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3803 - val_loss: 0.3864\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3776 - val_loss: 0.3859\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3751 - val_loss: 0.3861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2322/2322 [==============================] - 0s 30us/sample - loss: 0.3799\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 98us/sample - loss: 1.2458 - val_loss: 0.7524\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.6563 - val_loss: 0.6603\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.5813 - val_loss: 0.5893\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.5295 - val_loss: 0.5470\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4947 - val_loss: 0.5087\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4696 - val_loss: 0.4731\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4524 - val_loss: 0.4550\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4392 - val_loss: 0.4445\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4293 - val_loss: 0.4325\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4217 - val_loss: 0.4235\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.4147 - val_loss: 0.4157\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.4091 - val_loss: 0.4125\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.4041 - val_loss: 0.4070\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3998 - val_loss: 0.4059\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3957 - val_loss: 0.4015\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3928 - val_loss: 0.3971\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.3900 - val_loss: 0.3954\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3865 - val_loss: 0.3971\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3844 - val_loss: 0.3978\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 1s 62us/sample - loss: 0.3811 - val_loss: 0.3946\n",
      "2322/2322 [==============================] - 0s 30us/sample - loss: 0.3822\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 98us/sample - loss: 1.1898 - val_loss: 0.7022\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 1s 61us/sample - loss: 0.6085 - val_loss: 0.6070\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.5435 - val_loss: 0.5523\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.5020 - val_loss: 0.5116\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4732 - val_loss: 0.4817\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4516 - val_loss: 0.4568\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4373 - val_loss: 0.4417\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4265 - val_loss: 0.4345\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4180 - val_loss: 0.4329\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4104 - val_loss: 0.4196\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.4037 - val_loss: 0.4123\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.3983 - val_loss: 0.4087\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.3933 - val_loss: 0.4044\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 60us/sample - loss: 0.3884 - val_loss: 0.4050\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - ETA: 0s - loss: 0.385 - 1s 60us/sample - loss: 0.3842 - val_loss: 0.3973\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 63us/sample - loss: 0.3804 - val_loss: 0.3984\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 1s 64us/sample - loss: 0.3767 - val_loss: 0.4009\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3733 - val_loss: 0.3929\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3709 - val_loss: 0.3949\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3682 - val_loss: 0.3967\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.3890\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 72us/sample - loss: 1.5295 - val_loss: 0.8296\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6783 - val_loss: 0.5812\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5262 - val_loss: 0.5510\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4904 - val_loss: 0.5081\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4663 - val_loss: 0.4721\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4472 - val_loss: 0.4508\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4346 - val_loss: 0.4432\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4242 - val_loss: 0.4247\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.4140 - val_loss: 0.4140\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4056 - val_loss: 0.4161\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3989 - val_loss: 0.4031\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3929 - val_loss: 0.4022\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.3878 - val_loss: 0.3998\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3830 - val_loss: 0.3870\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3789 - val_loss: 0.3869\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3758 - val_loss: 0.3853\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3711 - val_loss: 0.3814\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3680 - val_loss: 0.3798\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.3658 - val_loss: 0.3812\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.3908\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 82us/sample - loss: 2.7817 - val_loss: 1.2092\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.9864 - val_loss: 0.9243\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.8133 - val_loss: 0.8154\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.7369 - val_loss: 0.7519\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.6930 - val_loss: 0.7130\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6616 - val_loss: 0.6813\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6356 - val_loss: 0.6577\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6136 - val_loss: 0.6293\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.5932 - val_loss: 0.6043\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5740 - val_loss: 0.5830\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5559 - val_loss: 0.5672\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5392 - val_loss: 0.5476\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5240 - val_loss: 0.5319\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5106 - val_loss: 0.5125\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4985 - val_loss: 0.4998\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4880 - val_loss: 0.4901\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4787 - val_loss: 0.4802\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4698 - val_loss: 0.4694\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4623 - val_loss: 0.4598\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4555 - val_loss: 0.4564\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4489 - val_loss: 0.4481\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4426 - val_loss: 0.4391\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4371 - val_loss: 0.4337\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4315 - val_loss: 0.4283\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4265 - val_loss: 0.4272\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4213 - val_loss: 0.4189\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4164 - val_loss: 0.4141\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4118 - val_loss: 0.4108\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4077 - val_loss: 0.4052\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4041 - val_loss: 0.4037\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4000 - val_loss: 0.3979\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3972 - val_loss: 0.3987\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3942 - val_loss: 0.3937\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3909 - val_loss: 0.3917\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3885 - val_loss: 0.3901\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3864 - val_loss: 0.3884\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3830 - val_loss: 0.3882\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3815 - val_loss: 0.3898\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.3523\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 84us/sample - loss: 2.3352 - val_loss: 1.3098\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.9943 - val_loss: 0.7813\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6782 - val_loss: 0.6919\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6212 - val_loss: 0.6503\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5882 - val_loss: 0.6167\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5617 - val_loss: 0.5940\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5408 - val_loss: 0.5695\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.5233 - val_loss: 0.5475\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5072 - val_loss: 0.5334\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4942 - val_loss: 0.5145\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4824 - val_loss: 0.5008\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4719 - val_loss: 0.4898\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4625 - val_loss: 0.4772\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4541 - val_loss: 0.4678\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4469 - val_loss: 0.4591\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4399 - val_loss: 0.4538\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4343 - val_loss: 0.4449\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4285 - val_loss: 0.4351\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4236 - val_loss: 0.4361\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4192 - val_loss: 0.4263\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4146 - val_loss: 0.4199\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4107 - val_loss: 0.4157\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4066 - val_loss: 0.4113\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4033 - val_loss: 0.4083\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3999 - val_loss: 0.4036\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3971 - val_loss: 0.3993\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3941 - val_loss: 0.3953\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3915 - val_loss: 0.3947\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3889 - val_loss: 0.3919\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3865 - val_loss: 0.3906\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3847 - val_loss: 0.3894\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3820 - val_loss: 0.3877\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.3802 - val_loss: 0.3849\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3782 - val_loss: 0.3832\n",
      "2322/2322 [==============================] - 0s 26us/sample - loss: 0.3822\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 109us/sample - loss: 2.7203 - val_loss: 1.2960\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.9784 - val_loss: 0.8502\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.7162 - val_loss: 0.7050\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 1s 58us/sample - loss: 0.6293 - val_loss: 0.6558\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5986 - val_loss: 0.6347\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5795 - val_loss: 0.6227\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5643 - val_loss: 0.6048\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5506 - val_loss: 0.5872\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5383 - val_loss: 0.5742\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - ETA: 0s - loss: 0.531 - 1s 54us/sample - loss: 0.5269 - val_loss: 0.5619\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5165 - val_loss: 0.5519\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5068 - val_loss: 0.5430\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4980 - val_loss: 0.5306\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4893 - val_loss: 0.5231\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4815 - val_loss: 0.5130\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4743 - val_loss: 0.5036\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4677 - val_loss: 0.4953\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4618 - val_loss: 0.4906\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4568 - val_loss: 0.4822\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4516 - val_loss: 0.4747\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4474 - val_loss: 0.4772\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4434 - val_loss: 0.4739\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4399 - val_loss: 0.4621\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4363 - val_loss: 0.4578\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4334 - val_loss: 0.4506\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4304 - val_loss: 0.4492\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4276 - val_loss: 0.4429\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4249 - val_loss: 0.4392\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4227 - val_loss: 0.4371\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4198 - val_loss: 0.4369\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4174 - val_loss: 0.4303\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4149 - val_loss: 0.4321\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4131 - val_loss: 0.4269\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4108 - val_loss: 0.4216\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 1s 57us/sample - loss: 0.4088 - val_loss: 0.4180\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4066 - val_loss: 0.4190\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4045 - val_loss: 0.4144\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4032 - val_loss: 0.4182\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4013 - val_loss: 0.4113\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3995 - val_loss: 0.4108\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.3979 - val_loss: 0.4089\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3962 - val_loss: 0.4036\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3945 - val_loss: 0.4067\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3929 - val_loss: 0.4040\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3906 - val_loss: 0.3973\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3900 - val_loss: 0.3959\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3881 - val_loss: 0.3947\n",
      "2322/2322 [==============================] - 0s 27us/sample - loss: 0.3879\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 82us/sample - loss: 2.4837 - val_loss: 1.2596\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.9546 - val_loss: 0.8767\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.7302 - val_loss: 0.7380\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6473 - val_loss: 0.6776\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6085 - val_loss: 0.6458\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.5823 - val_loss: 0.6207\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5620 - val_loss: 0.5966\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5439 - val_loss: 0.5781\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5279 - val_loss: 0.5565\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5145 - val_loss: 0.5406\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5020 - val_loss: 0.5301\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4921 - val_loss: 0.5160\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4831 - val_loss: 0.5095\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4751 - val_loss: 0.4981\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4672 - val_loss: 0.4930\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4610 - val_loss: 0.4892\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4554 - val_loss: 0.4725\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.4501 - val_loss: 0.4664\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4449 - val_loss: 0.4614\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4407 - val_loss: 0.4546\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4367 - val_loss: 0.4497\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4328 - val_loss: 0.4484\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4289 - val_loss: 0.4411\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4255 - val_loss: 0.4401\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4220 - val_loss: 0.4322\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4191 - val_loss: 0.4281\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4159 - val_loss: 0.4285\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4134 - val_loss: 0.4256\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4103 - val_loss: 0.4178\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4080 - val_loss: 0.4205\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4053 - val_loss: 0.4177\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4025 - val_loss: 0.4098\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4004 - val_loss: 0.4064\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3983 - val_loss: 0.4078\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3957 - val_loss: 0.4027\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3940 - val_loss: 0.4017\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3920 - val_loss: 0.4011\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3896 - val_loss: 0.3955\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3880 - val_loss: 0.3952\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3859 - val_loss: 0.3925\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3840 - val_loss: 0.3958\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3823 - val_loss: 0.3912\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3805 - val_loss: 0.3930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2322/2322 [==============================] - 0s 28us/sample - loss: 0.3985\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 83us/sample - loss: 2.1040 - val_loss: 0.9614\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.7869 - val_loss: 0.7125\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6403 - val_loss: 0.6550\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5956 - val_loss: 0.6149\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5663 - val_loss: 0.5893\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 1s 55us/sample - loss: 0.5443 - val_loss: 0.5640\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5263 - val_loss: 0.5469\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5117 - val_loss: 0.5384\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4990 - val_loss: 0.5198\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4879 - val_loss: 0.5074\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4791 - val_loss: 0.4976\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 1s 59us/sample - loss: 0.4700 - val_loss: 0.4965\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4625 - val_loss: 0.4814\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4559 - val_loss: 0.4719\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4500 - val_loss: 0.4648\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4445 - val_loss: 0.4567\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4400 - val_loss: 0.4589\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4345 - val_loss: 0.4443\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4314 - val_loss: 0.4437\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4271 - val_loss: 0.4352\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4236 - val_loss: 0.4365\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4199 - val_loss: 0.4299\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4172 - val_loss: 0.4277\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4138 - val_loss: 0.4211\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4109 - val_loss: 0.4193\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4080 - val_loss: 0.4137\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4060 - val_loss: 0.4134\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4036 - val_loss: 0.4105\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4008 - val_loss: 0.4105\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3982 - val_loss: 0.4070\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3956 - val_loss: 0.4008\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3931 - val_loss: 0.4041\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3913 - val_loss: 0.4011\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3888 - val_loss: 0.3979\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3870 - val_loss: 0.3969\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3847 - val_loss: 0.3969\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 1s 57us/sample - loss: 0.3836 - val_loss: 0.3938\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3816 - val_loss: 0.3873\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3802 - val_loss: 0.3892\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3784 - val_loss: 0.3894\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.4131\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 82us/sample - loss: 1.8466 - val_loss: 0.9054\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.7356 - val_loss: 0.7133\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6446 - val_loss: 0.6549\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6056 - val_loss: 0.6219\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5772 - val_loss: 0.5887\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5539 - val_loss: 0.5624\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5337 - val_loss: 0.5413\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.5157 - val_loss: 0.5204\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4988 - val_loss: 0.5011\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4833 - val_loss: 0.4849\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4689 - val_loss: 0.4653\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4558 - val_loss: 0.4509\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4432 - val_loss: 0.4385\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4326 - val_loss: 0.4249\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4237 - val_loss: 0.4153\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4155 - val_loss: 0.4080\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4088 - val_loss: 0.4038\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4022 - val_loss: 0.3992\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3968 - val_loss: 0.3949\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3920 - val_loss: 0.3905\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3885 - val_loss: 0.3889\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3844 - val_loss: 0.3844\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3808 - val_loss: 0.3820\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3783 - val_loss: 0.3872\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3749 - val_loss: 0.3793\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3719 - val_loss: 0.3784\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.3693 - val_loss: 0.3743\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3675 - val_loss: 0.3730\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3650 - val_loss: 0.3732\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3631 - val_loss: 0.3704\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3610 - val_loss: 0.3697\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3586 - val_loss: 0.3693\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.3491\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 86us/sample - loss: 1.5825 - val_loss: 0.8403\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.7265 - val_loss: 0.7041\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6505 - val_loss: 0.6478\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.6028 - val_loss: 0.6103\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.5636 - val_loss: 0.5683\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5312 - val_loss: 0.5511\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5035 - val_loss: 0.5078\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4821 - val_loss: 0.4878\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4637 - val_loss: 0.4693\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4500 - val_loss: 0.4529\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4385 - val_loss: 0.4435\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4283 - val_loss: 0.4347\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4197 - val_loss: 0.4227\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4121 - val_loss: 0.4202\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4057 - val_loss: 0.4146\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4001 - val_loss: 0.4036\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3945 - val_loss: 0.4017\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3901 - val_loss: 0.3969\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3860 - val_loss: 0.3939\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3826 - val_loss: 0.3912\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3793 - val_loss: 0.3963\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3756 - val_loss: 0.3909\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3735 - val_loss: 0.3826\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3705 - val_loss: 0.3823\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3682 - val_loss: 0.3783\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 1s 56us/sample - loss: 0.3654 - val_loss: 0.3866\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3633 - val_loss: 0.3812\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3601 - val_loss: 0.3923\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3595 - val_loss: 0.3728\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3569 - val_loss: 0.3722\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.3584\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 85us/sample - loss: 1.7334 - val_loss: 0.8579\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.7111 - val_loss: 0.6775\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6223 - val_loss: 0.6276\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5844 - val_loss: 0.5913\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.5527 - val_loss: 0.5610\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5267 - val_loss: 0.5362\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.5041 - val_loss: 0.5156\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4850 - val_loss: 0.4908\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4675 - val_loss: 0.4703\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4533 - val_loss: 0.4571\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4409 - val_loss: 0.4559\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4304 - val_loss: 0.4266\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4215 - val_loss: 0.4225\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4135 - val_loss: 0.4097\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4074 - val_loss: 0.4051\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4020 - val_loss: 0.3991\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3975 - val_loss: 0.3954\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3932 - val_loss: 0.3937\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3897 - val_loss: 0.3880\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3861 - val_loss: 0.3921\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3839 - val_loss: 0.3905\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3806 - val_loss: 0.3809\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3780 - val_loss: 0.3802\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3759 - val_loss: 0.3803\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3758\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 86us/sample - loss: 1.5674 - val_loss: 0.7874\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6798 - val_loss: 0.6863\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6135 - val_loss: 0.6460\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5788 - val_loss: 0.6128\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5508 - val_loss: 0.5818\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5261 - val_loss: 0.5573\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5030 - val_loss: 0.5270\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 1s 54us/sample - loss: 0.4838 - val_loss: 0.5053\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4658 - val_loss: 0.4823\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4516 - val_loss: 0.4644\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4399 - val_loss: 0.4497\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 54us/sample - loss: 0.4302 - val_loss: 0.4447\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4222 - val_loss: 0.4374\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4161 - val_loss: 0.4216\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4105 - val_loss: 0.4152\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4056 - val_loss: 0.4167\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4016 - val_loss: 0.4095\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3978 - val_loss: 0.4029\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3946 - val_loss: 0.4000\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3915 - val_loss: 0.3999\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3884 - val_loss: 0.3994\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3851 - val_loss: 0.3917\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3825 - val_loss: 0.3947\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3801 - val_loss: 0.3915\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3773 - val_loss: 0.3935\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3750 - val_loss: 0.3851\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3727 - val_loss: 0.3824\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3702 - val_loss: 0.3806\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3678 - val_loss: 0.3814\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3660 - val_loss: 0.3819\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3643 - val_loss: 0.3767\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3780\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 88us/sample - loss: 1.8038 - val_loss: 0.7868\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6611 - val_loss: 0.6234\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5696 - val_loss: 0.5718\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5300 - val_loss: 0.5424\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5032 - val_loss: 0.5105\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4818 - val_loss: 0.4842\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4656 - val_loss: 0.4694\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4519 - val_loss: 0.4582\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4410 - val_loss: 0.4423\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4305 - val_loss: 0.4360\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4241 - val_loss: 0.4256\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4167 - val_loss: 0.4232\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4112 - val_loss: 0.4099\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.4058 - val_loss: 0.4069\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4011 - val_loss: 0.4044\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3964 - val_loss: 0.3999\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3925 - val_loss: 0.3963\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3892 - val_loss: 0.3984\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3865 - val_loss: 0.3964\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3827 - val_loss: 0.3930\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3804 - val_loss: 0.3901\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 53us/sample - loss: 0.3777 - val_loss: 0.3887\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.4070\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 2.5354 - val_loss: 1.6206\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.1750 - val_loss: 1.0721\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9069 - val_loss: 0.9153\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.8190 - val_loss: 0.8513\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7760 - val_loss: 0.8103\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7451 - val_loss: 0.7812\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7201 - val_loss: 0.7561\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6982 - val_loss: 0.7337\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6786 - val_loss: 0.7144\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6609 - val_loss: 0.6963\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6447 - val_loss: 0.6793\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6297 - val_loss: 0.6626\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6165 - val_loss: 0.6488\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6040 - val_loss: 0.6353\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5927 - val_loss: 0.6239\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5825 - val_loss: 0.6130\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5728 - val_loss: 0.6021\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5642 - val_loss: 0.5924\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5561 - val_loss: 0.5834\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5489 - val_loss: 0.5753\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5421 - val_loss: 0.5682\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5360 - val_loss: 0.5606\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5303 - val_loss: 0.5531\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5251 - val_loss: 0.5474\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5203 - val_loss: 0.5427\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5160 - val_loss: 0.5369\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5122 - val_loss: 0.5320\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5082 - val_loss: 0.5282\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5050 - val_loss: 0.5237\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5019 - val_loss: 0.5199\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4988 - val_loss: 0.5161\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4962 - val_loss: 0.5127\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4935 - val_loss: 0.5097\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4910 - val_loss: 0.5070\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4888 - val_loss: 0.5037\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4868 - val_loss: 0.5011\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4845 - val_loss: 0.4982\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4827 - val_loss: 0.4951\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4807 - val_loss: 0.4932\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4789 - val_loss: 0.4919\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4774 - val_loss: 0.4891\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4757 - val_loss: 0.4865\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4742 - val_loss: 0.4853\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4726 - val_loss: 0.4827\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4711 - val_loss: 0.4801\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4700 - val_loss: 0.4795\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.4684 - val_loss: 0.4771\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.4214\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 2.7580 - val_loss: 1.6952\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.2700 - val_loss: 1.1268\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9693 - val_loss: 0.9630\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8629 - val_loss: 0.8883\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8080 - val_loss: 0.8426\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7706 - val_loss: 0.8094\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7414 - val_loss: 0.7824\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7172 - val_loss: 0.7595\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6967 - val_loss: 0.7385\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6789 - val_loss: 0.7206\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6631 - val_loss: 0.7049\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6492 - val_loss: 0.6894\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6363 - val_loss: 0.6761\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6247 - val_loss: 0.6631\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6140 - val_loss: 0.6528\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6042 - val_loss: 0.6421\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5951 - val_loss: 0.6316\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5867 - val_loss: 0.6219\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5787 - val_loss: 0.6139\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5716 - val_loss: 0.6055\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5648 - val_loss: 0.5979\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5583 - val_loss: 0.5897\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5525 - val_loss: 0.5834\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5470 - val_loss: 0.5770\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5417 - val_loss: 0.5707\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5368 - val_loss: 0.5642\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5322 - val_loss: 0.5590\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5278 - val_loss: 0.5536\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5237 - val_loss: 0.5488\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5197 - val_loss: 0.5440\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5161 - val_loss: 0.5402\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5125 - val_loss: 0.5356\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5089 - val_loss: 0.5308\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5056 - val_loss: 0.5275\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5026 - val_loss: 0.5241\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4996 - val_loss: 0.5190\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4967 - val_loss: 0.5155\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4940 - val_loss: 0.5123\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4913 - val_loss: 0.5089\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4890 - val_loss: 0.5064\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4864 - val_loss: 0.5030\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.4840 - val_loss: 0.5001\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4818 - val_loss: 0.4981\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4796 - val_loss: 0.4950\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4775 - val_loss: 0.4923\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4755 - val_loss: 0.4900\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4734 - val_loss: 0.4863\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4715 - val_loss: 0.4849\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4695 - val_loss: 0.4813\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4679 - val_loss: 0.4797\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4660 - val_loss: 0.4772\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4643 - val_loss: 0.4756\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4626 - val_loss: 0.4733\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4610 - val_loss: 0.4710\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4593 - val_loss: 0.4685\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4578 - val_loss: 0.4671\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4563 - val_loss: 0.4670\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4549 - val_loss: 0.4635\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4534 - val_loss: 0.4623\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4519 - val_loss: 0.4596\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.4627\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 99us/sample - loss: 3.3365 - val_loss: 2.1800\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.5792 - val_loss: 1.2537\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.9986 - val_loss: 0.9186\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7883 - val_loss: 0.7939\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7101 - val_loss: 0.7422\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6758 - val_loss: 0.7164\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6551 - val_loss: 0.6992\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6391 - val_loss: 0.6833\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6254 - val_loss: 0.6690\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6124 - val_loss: 0.6552\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6007 - val_loss: 0.6434\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5896 - val_loss: 0.6323\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5788 - val_loss: 0.6203\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5691 - val_loss: 0.6091\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5599 - val_loss: 0.5986\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5512 - val_loss: 0.5902\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5434 - val_loss: 0.5811\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5358 - val_loss: 0.5723\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5288 - val_loss: 0.5659\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5227 - val_loss: 0.5579\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5168 - val_loss: 0.5510\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5114 - val_loss: 0.5442\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5065 - val_loss: 0.5381\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5019 - val_loss: 0.5326\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4976 - val_loss: 0.5273\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4937 - val_loss: 0.5222\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4900 - val_loss: 0.5184\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4865 - val_loss: 0.5140\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4833 - val_loss: 0.5098\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4803 - val_loss: 0.5050\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4775 - val_loss: 0.5027\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4750 - val_loss: 0.4992\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4725 - val_loss: 0.4958\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4701 - val_loss: 0.4935\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4680 - val_loss: 0.4900\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4659 - val_loss: 0.4878\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4640 - val_loss: 0.4848\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4621 - val_loss: 0.4834\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4604 - val_loss: 0.4807\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4588 - val_loss: 0.4787\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4572 - val_loss: 0.4775\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4557 - val_loss: 0.4753\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4541 - val_loss: 0.4720\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4529 - val_loss: 0.4708\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4515 - val_loss: 0.4688\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.4502\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 3.3932 - val_loss: 1.5711\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0529 - val_loss: 0.8812\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7511 - val_loss: 0.7543\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6797 - val_loss: 0.7120\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6474 - val_loss: 0.6892\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6260 - val_loss: 0.6726\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6100 - val_loss: 0.6585\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5973 - val_loss: 0.6470\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5859 - val_loss: 0.6359\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5762 - val_loss: 0.6265\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5674 - val_loss: 0.6173\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5596 - val_loss: 0.6090\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5524 - val_loss: 0.6007\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5460 - val_loss: 0.5946\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5404 - val_loss: 0.5879\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5354 - val_loss: 0.5825\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5305 - val_loss: 0.5765\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5259 - val_loss: 0.5712\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5219 - val_loss: 0.5673\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5181 - val_loss: 0.5628\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5147 - val_loss: 0.5583\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5115 - val_loss: 0.5540\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5083 - val_loss: 0.5502\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5054 - val_loss: 0.5468\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5024 - val_loss: 0.5434\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5002 - val_loss: 0.5401\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4977 - val_loss: 0.5380\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4953 - val_loss: 0.5350\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4931 - val_loss: 0.5325\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4911 - val_loss: 0.5299\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4892 - val_loss: 0.5267\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4871 - val_loss: 0.5240\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4854 - val_loss: 0.5218\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4836 - val_loss: 0.5211\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4821 - val_loss: 0.5178\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4804 - val_loss: 0.5161\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4788 - val_loss: 0.5137\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4772 - val_loss: 0.5111\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4757 - val_loss: 0.5095\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4743 - val_loss: 0.5082\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.5026\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 3.3401 - val_loss: 1.7183\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.2098 - val_loss: 1.0462\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8720 - val_loss: 0.8781\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7657 - val_loss: 0.8159\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7220 - val_loss: 0.7827\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6978 - val_loss: 0.7614\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6805 - val_loss: 0.7431\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6658 - val_loss: 0.7271\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6523 - val_loss: 0.7130\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6399 - val_loss: 0.6974\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6282 - val_loss: 0.6841\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6171 - val_loss: 0.6736\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6068 - val_loss: 0.6603\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5969 - val_loss: 0.6503\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5877 - val_loss: 0.6403\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5790 - val_loss: 0.6300\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5707 - val_loss: 0.6203\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5630 - val_loss: 0.6122\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5556 - val_loss: 0.6039\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5487 - val_loss: 0.5949\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5423 - val_loss: 0.5882\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5360 - val_loss: 0.5797\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5303 - val_loss: 0.5745\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5248 - val_loss: 0.5669\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5198 - val_loss: 0.5609\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5150 - val_loss: 0.5562\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5105 - val_loss: 0.5499\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5064 - val_loss: 0.5454\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5023 - val_loss: 0.5393\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4987 - val_loss: 0.5353\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4952 - val_loss: 0.5310\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4919 - val_loss: 0.5260\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4888 - val_loss: 0.5231\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4859 - val_loss: 0.5195\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4832 - val_loss: 0.5159\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4806 - val_loss: 0.5116\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4781 - val_loss: 0.5086\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4757 - val_loss: 0.5059\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4735 - val_loss: 0.5019\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4713 - val_loss: 0.4996\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4691 - val_loss: 0.4977\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4672 - val_loss: 0.4947\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4652 - val_loss: 0.4917\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4634 - val_loss: 0.4880\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4615 - val_loss: 0.4874\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4598 - val_loss: 0.4847\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.4582 - val_loss: 0.4830\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.4565 - val_loss: 0.4796\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.4550 - val_loss: 0.4782\n",
      "2322/2322 [==============================] - 0s 26us/sample - loss: 0.4793\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 80us/sample - loss: 1.3786 - val_loss: 0.6449\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.5880 - val_loss: 0.5662\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.4909 - val_loss: 0.4433\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4395 - val_loss: 0.4383\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4163 - val_loss: 0.4052\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3996 - val_loss: 0.3965\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3866 - val_loss: 0.3910\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3840 - val_loss: 0.3877\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3681 - val_loss: 0.3699\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3611 - val_loss: 0.4127\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3554 - val_loss: 0.4036\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3478 - val_loss: 0.3616\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3449 - val_loss: 0.3727\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3414 - val_loss: 0.3639\n",
      "2322/2322 [==============================] - 0s 24us/sample - loss: 0.3343\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 77us/sample - loss: 0.8518 - val_loss: 0.5784\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5216 - val_loss: 0.4917\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4482 - val_loss: 0.4204\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.4070 - val_loss: 0.4076\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3877 - val_loss: 0.4045\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3760 - val_loss: 0.3751\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3674 - val_loss: 0.3671\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3607 - val_loss: 0.3986\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3540 - val_loss: 0.3688\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3528 - val_loss: 0.3673\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3485 - val_loss: 0.3699\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.3566\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 77us/sample - loss: 0.8306 - val_loss: 0.5405\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4621 - val_loss: 0.4340\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4060 - val_loss: 0.3860\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3850 - val_loss: 0.3815\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3709 - val_loss: 0.4019\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3621 - val_loss: 0.3865\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3565 - val_loss: 0.4026\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3495 - val_loss: 0.4188\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.4035\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 77us/sample - loss: 0.8266 - val_loss: 0.6545\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5523 - val_loss: 0.4704\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.4406 - val_loss: 0.4279\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4157 - val_loss: 0.4043\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3992 - val_loss: 0.3985\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3894 - val_loss: 0.3877\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3799 - val_loss: 0.3844\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3736 - val_loss: 0.3969\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3658 - val_loss: 0.3745\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 51us/sample - loss: 0.3607 - val_loss: 0.4239\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3545 - val_loss: 0.3910\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3490 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3454 - val_loss: 0.3675\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3412 - val_loss: 0.4127\n",
      "2322/2322 [==============================] - 0s 25us/sample - loss: 0.3872\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 79us/sample - loss: 1.0673 - val_loss: 0.6099\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.5131 - val_loss: 0.5346\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4521 - val_loss: 0.4622\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.4164 - val_loss: 0.4255\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3919 - val_loss: 0.3862\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3773 - val_loss: 0.3785\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3679 - val_loss: 0.3863\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.3668 - val_loss: 0.4091\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3588 - val_loss: 0.3964\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3493 - val_loss: 0.3596\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3411 - val_loss: 0.3770\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.3373 - val_loss: 0.3620\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.3361 - val_loss: 0.3715\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3303 - val_loss: 0.3561\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.3270 - val_loss: 0.3683\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.3550\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 72us/sample - loss: 4.8933 - val_loss: 4.3844\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 3.7341 - val_loss: 3.4252\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 2.9161 - val_loss: 2.7357\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 2.3306 - val_loss: 2.2346\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.9055 - val_loss: 1.8675\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 1.5973 - val_loss: 1.5956\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.3693 - val_loss: 1.3952\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.2031 - val_loss: 1.2471\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.0818 - val_loss: 1.1370\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9925 - val_loss: 1.0538\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9262 - val_loss: 0.9916\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.8769 - val_loss: 0.9440\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.8397 - val_loss: 0.9071\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8115 - val_loss: 0.8779\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7894 - val_loss: 0.8547\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7720 - val_loss: 0.8358\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7580 - val_loss: 0.8203\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7465 - val_loss: 0.8071\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7368 - val_loss: 0.7958\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7285 - val_loss: 0.7860\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7212 - val_loss: 0.7773\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7148 - val_loss: 0.7696\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7090 - val_loss: 0.7626\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7037 - val_loss: 0.7562\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6988 - val_loss: 0.7504\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6942 - val_loss: 0.7450\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6899 - val_loss: 0.7398\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6859 - val_loss: 0.7350\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6820 - val_loss: 0.7304\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6783 - val_loss: 0.7261\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6747 - val_loss: 0.7218\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6713 - val_loss: 0.7179\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6680 - val_loss: 0.7141\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6648 - val_loss: 0.7104\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6616 - val_loss: 0.7068\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6586 - val_loss: 0.7034\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6556 - val_loss: 0.7000\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6527 - val_loss: 0.6968\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6498 - val_loss: 0.6936\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6470 - val_loss: 0.6905\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6443 - val_loss: 0.6874\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6416 - val_loss: 0.6845\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6390 - val_loss: 0.6817\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6365 - val_loss: 0.6789\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6340 - val_loss: 0.6760\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6315 - val_loss: 0.6731\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6291 - val_loss: 0.6706\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 0.6268 - val_loss: 0.6680\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6245 - val_loss: 0.6655\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6222 - val_loss: 0.6630\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6200 - val_loss: 0.6603\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6178 - val_loss: 0.6579\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6156 - val_loss: 0.6555\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6135 - val_loss: 0.6533\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6114 - val_loss: 0.6509\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6094 - val_loss: 0.6487\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6074 - val_loss: 0.6466\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6054 - val_loss: 0.6446\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6034 - val_loss: 0.6423\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6015 - val_loss: 0.6401\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5996 - val_loss: 0.6381\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5978 - val_loss: 0.6362\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5960 - val_loss: 0.6341\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5942 - val_loss: 0.6321\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5924 - val_loss: 0.6301\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5907 - val_loss: 0.6283\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5890 - val_loss: 0.6265\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.5399\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 71us/sample - loss: 6.9741 - val_loss: 6.0524\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 4.9019 - val_loss: 4.4460\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 3.6545 - val_loss: 3.4259\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 2.8553 - val_loss: 2.7503\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 2.3219 - val_loss: 2.2843\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.9514 - val_loss: 1.9520\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.6866 - val_loss: 1.7085\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.4910 - val_loss: 1.5244\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 1.3419 - val_loss: 1.3821\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.2264 - val_loss: 1.2701\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.1349 - val_loss: 1.1807\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.0614 - val_loss: 1.1082\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0017 - val_loss: 1.0495\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9530 - val_loss: 1.0010\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.9127 - val_loss: 0.9605\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.8789 - val_loss: 0.9267\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8505 - val_loss: 0.8983\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8266 - val_loss: 0.8741\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8061 - val_loss: 0.8538\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7886 - val_loss: 0.8363\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7735 - val_loss: 0.8211\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7602 - val_loss: 0.8078\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7485 - val_loss: 0.7960\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7381 - val_loss: 0.7856\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7287 - val_loss: 0.7761\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7201 - val_loss: 0.7676\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7125 - val_loss: 0.7598\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7054 - val_loss: 0.7528\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6988 - val_loss: 0.7462\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6927 - val_loss: 0.7401\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6870 - val_loss: 0.7344\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6816 - val_loss: 0.7290\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6766 - val_loss: 0.7239\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6717 - val_loss: 0.7190\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6671 - val_loss: 0.7143\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6627 - val_loss: 0.7098\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6584 - val_loss: 0.7056\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6544 - val_loss: 0.7015\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6504 - val_loss: 0.6975\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6466 - val_loss: 0.6936\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6429 - val_loss: 0.6899\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6394 - val_loss: 0.6863\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6359 - val_loss: 0.6828\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6325 - val_loss: 0.6794\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6293 - val_loss: 0.6760\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6261 - val_loss: 0.6729\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6230 - val_loss: 0.6697\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6200 - val_loss: 0.6666\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6170 - val_loss: 0.6636\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6141 - val_loss: 0.6605\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.6113 - val_loss: 0.6577\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6086 - val_loss: 0.6548\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6059 - val_loss: 0.6520\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6033 - val_loss: 0.6493\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6008 - val_loss: 0.6467\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5983 - val_loss: 0.6440\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5958 - val_loss: 0.6415\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5934 - val_loss: 0.6389\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5910 - val_loss: 0.6365\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5888 - val_loss: 0.6340\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5865 - val_loss: 0.6315\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5842 - val_loss: 0.6291\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5821 - val_loss: 0.6268\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5799 - val_loss: 0.6245\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5778 - val_loss: 0.6222\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5757 - val_loss: 0.6200\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5737 - val_loss: 0.6177\n",
      "Epoch 68/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5717 - val_loss: 0.6155\n",
      "Epoch 69/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5697 - val_loss: 0.6133\n",
      "Epoch 70/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5678 - val_loss: 0.6113\n",
      "Epoch 71/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5659 - val_loss: 0.6092\n",
      "Epoch 72/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5640 - val_loss: 0.6071\n",
      "Epoch 73/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5622 - val_loss: 0.6052\n",
      "Epoch 74/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5604 - val_loss: 0.6031\n",
      "Epoch 75/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5587 - val_loss: 0.6011\n",
      "Epoch 76/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5569 - val_loss: 0.5992\n",
      "Epoch 77/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5552 - val_loss: 0.5974\n",
      "Epoch 78/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5535 - val_loss: 0.5955\n",
      "Epoch 79/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5519 - val_loss: 0.5937\n",
      "Epoch 80/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5503 - val_loss: 0.5919\n",
      "2322/2322 [==============================] - 0s 21us/sample - loss: 0.5535\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 69us/sample - loss: 6.2132 - val_loss: 5.1211\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 4.1050 - val_loss: 3.5735\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 2.9391 - val_loss: 2.6667\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 2.2442 - val_loss: 2.0993\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.8075 - val_loss: 1.7336\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 50us/sample - loss: 1.5189 - val_loss: 1.4812\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.3203 - val_loss: 1.3058\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.1793 - val_loss: 1.1791\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0773 - val_loss: 1.0863\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0009 - val_loss: 1.0165\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.9435 - val_loss: 0.9645\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8991 - val_loss: 0.9240\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.8642 - val_loss: 0.8919\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8365 - val_loss: 0.8665\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8140 - val_loss: 0.8457\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7955 - val_loss: 0.8289\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7802 - val_loss: 0.8144\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7672 - val_loss: 0.8019\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7560 - val_loss: 0.7914\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7464 - val_loss: 0.7825\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7380 - val_loss: 0.7744\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7305 - val_loss: 0.7673\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7239 - val_loss: 0.7610\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7179 - val_loss: 0.7552\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7125 - val_loss: 0.7500\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7075 - val_loss: 0.7451\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7029 - val_loss: 0.7404\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6987 - val_loss: 0.7362\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6946 - val_loss: 0.7324\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6909 - val_loss: 0.7286\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6873 - val_loss: 0.7250\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6839 - val_loss: 0.7217\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6807 - val_loss: 0.7184\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6777 - val_loss: 0.7153\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6747 - val_loss: 0.7122\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6719 - val_loss: 0.7094\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6692 - val_loss: 0.7063\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6665 - val_loss: 0.7037\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6640 - val_loss: 0.7010\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6615 - val_loss: 0.6985\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6590 - val_loss: 0.6958\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6566 - val_loss: 0.6933\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6543 - val_loss: 0.6910\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6520 - val_loss: 0.6888\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6498 - val_loss: 0.6862\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6476 - val_loss: 0.6837\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6455 - val_loss: 0.6816\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6434 - val_loss: 0.6796\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6414 - val_loss: 0.6775\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6393 - val_loss: 0.6753\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6374 - val_loss: 0.6732\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6354 - val_loss: 0.6710\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6335 - val_loss: 0.6691\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6316 - val_loss: 0.6671\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6297 - val_loss: 0.6653\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6279 - val_loss: 0.6634\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6260 - val_loss: 0.6612\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6243 - val_loss: 0.6594\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6225 - val_loss: 0.6576\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.6245\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 70us/sample - loss: 4.9470 - val_loss: 4.5866\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 3.8743 - val_loss: 3.7031\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 3.1213 - val_loss: 3.0661\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 2.5728 - val_loss: 2.5902\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 2.1664 - val_loss: 2.2296\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.8615 - val_loss: 1.9519\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.6297 - val_loss: 1.7340\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.4507 - val_loss: 1.5614\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 1.3120 - val_loss: 1.4241\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 1.2035 - val_loss: 1.3131\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.1174 - val_loss: 1.2227\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 1.0482 - val_loss: 1.1488\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.9922 - val_loss: 1.0880\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.9467 - val_loss: 1.0372\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9088 - val_loss: 0.9944\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.8769 - val_loss: 0.9583\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.8501 - val_loss: 0.9278\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8272 - val_loss: 0.9017\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8075 - val_loss: 0.8792\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7904 - val_loss: 0.8598\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7754 - val_loss: 0.8430\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7623 - val_loss: 0.8283\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7506 - val_loss: 0.8154\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7402 - val_loss: 0.8039\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7308 - val_loss: 0.7938\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7224 - val_loss: 0.7848\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7148 - val_loss: 0.7768\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.7079 - val_loss: 0.7695\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7016 - val_loss: 0.7630\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6957 - val_loss: 0.7569\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6903 - val_loss: 0.7513\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6853 - val_loss: 0.7462\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6806 - val_loss: 0.7415\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6762 - val_loss: 0.7371\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6721 - val_loss: 0.7328\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6682 - val_loss: 0.7289\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6645 - val_loss: 0.7251\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6609 - val_loss: 0.7215\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6575 - val_loss: 0.7181\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6542 - val_loss: 0.7148\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6511 - val_loss: 0.7117\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6481 - val_loss: 0.7086\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6452 - val_loss: 0.7057\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6424 - val_loss: 0.7027\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6397 - val_loss: 0.6999\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6371 - val_loss: 0.6972\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6345 - val_loss: 0.6944\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6320 - val_loss: 0.6918\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6295 - val_loss: 0.6892\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6271 - val_loss: 0.6866\n",
      "Epoch 51/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6248 - val_loss: 0.6841\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.6225 - val_loss: 0.6816\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6202 - val_loss: 0.6792\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6180 - val_loss: 0.6767\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6158 - val_loss: 0.6743\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6137 - val_loss: 0.6720\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6116 - val_loss: 0.6697\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6095 - val_loss: 0.6674\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6075 - val_loss: 0.6650\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6054 - val_loss: 0.6628\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6035 - val_loss: 0.6605\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6015 - val_loss: 0.6584\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5996 - val_loss: 0.6562\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5977 - val_loss: 0.6540\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5959 - val_loss: 0.6519\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5940 - val_loss: 0.6499\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5922 - val_loss: 0.6478\n",
      "Epoch 68/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5904 - val_loss: 0.6457\n",
      "Epoch 69/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5886 - val_loss: 0.6437\n",
      "Epoch 70/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5869 - val_loss: 0.6417\n",
      "Epoch 71/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5852 - val_loss: 0.6397\n",
      "Epoch 72/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5835 - val_loss: 0.6377\n",
      "Epoch 73/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.5818 - val_loss: 0.6358\n",
      "Epoch 74/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5802 - val_loss: 0.6339\n",
      "Epoch 75/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5785 - val_loss: 0.6320\n",
      "Epoch 76/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5769 - val_loss: 0.6301\n",
      "Epoch 77/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5754 - val_loss: 0.6283\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.6316\n",
      "Train on 9288 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "9288/9288 [==============================] - 1s 68us/sample - loss: 6.3564 - val_loss: 5.7241\n",
      "Epoch 2/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 4.7834 - val_loss: 4.4277\n",
      "Epoch 3/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 3.7312 - val_loss: 3.5311\n",
      "Epoch 4/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 2.9952 - val_loss: 2.8897\n",
      "Epoch 5/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 2.4638 - val_loss: 2.4178\n",
      "Epoch 6/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 2.0706 - val_loss: 2.0660\n",
      "Epoch 7/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.7798 - val_loss: 1.8024\n",
      "Epoch 8/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.5608 - val_loss: 1.6011\n",
      "Epoch 9/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 1.3939 - val_loss: 1.4458\n",
      "Epoch 10/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.2669 - val_loss: 1.3261\n",
      "Epoch 11/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 1.1695 - val_loss: 1.2337\n",
      "Epoch 12/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0944 - val_loss: 1.1610\n",
      "Epoch 13/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 1.0364 - val_loss: 1.1038\n",
      "Epoch 14/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.9908 - val_loss: 1.0583\n",
      "Epoch 15/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.9544 - val_loss: 1.0214\n",
      "Epoch 16/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.9251 - val_loss: 0.9913\n",
      "Epoch 17/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.9010 - val_loss: 0.9665\n",
      "Epoch 18/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8810 - val_loss: 0.9455\n",
      "Epoch 19/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.8640 - val_loss: 0.9277\n",
      "Epoch 20/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.8495 - val_loss: 0.9126\n",
      "Epoch 21/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.8369 - val_loss: 0.8992\n",
      "Epoch 22/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.8257 - val_loss: 0.8874\n",
      "Epoch 23/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.8157 - val_loss: 0.8768\n",
      "Epoch 24/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.8067 - val_loss: 0.8673\n",
      "Epoch 25/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7984 - val_loss: 0.8586\n",
      "Epoch 26/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7907 - val_loss: 0.8505\n",
      "Epoch 27/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7836 - val_loss: 0.8430\n",
      "Epoch 28/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7768 - val_loss: 0.8361\n",
      "Epoch 29/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7705 - val_loss: 0.8294\n",
      "Epoch 30/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7644 - val_loss: 0.8230\n",
      "Epoch 31/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7586 - val_loss: 0.8171\n",
      "Epoch 32/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7530 - val_loss: 0.8113\n",
      "Epoch 33/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.7476 - val_loss: 0.8058\n",
      "Epoch 34/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7424 - val_loss: 0.8005\n",
      "Epoch 35/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7374 - val_loss: 0.7954\n",
      "Epoch 36/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7325 - val_loss: 0.7905\n",
      "Epoch 37/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7278 - val_loss: 0.7857\n",
      "Epoch 38/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.7232 - val_loss: 0.7809\n",
      "Epoch 39/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.7187 - val_loss: 0.7764\n",
      "Epoch 40/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7143 - val_loss: 0.7720\n",
      "Epoch 41/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7101 - val_loss: 0.7677\n",
      "Epoch 42/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7060 - val_loss: 0.7635\n",
      "Epoch 43/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.7020 - val_loss: 0.7592\n",
      "Epoch 44/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6981 - val_loss: 0.7552\n",
      "Epoch 45/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6943 - val_loss: 0.7513\n",
      "Epoch 46/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6905 - val_loss: 0.7474\n",
      "Epoch 47/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6869 - val_loss: 0.7436\n",
      "Epoch 48/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6833 - val_loss: 0.7398\n",
      "Epoch 49/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6798 - val_loss: 0.7362\n",
      "Epoch 50/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6764 - val_loss: 0.7327\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6731 - val_loss: 0.7292\n",
      "Epoch 52/100\n",
      "9288/9288 [==============================] - 0s 52us/sample - loss: 0.6698 - val_loss: 0.7256\n",
      "Epoch 53/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6665 - val_loss: 0.7221\n",
      "Epoch 54/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6634 - val_loss: 0.7188\n",
      "Epoch 55/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6603 - val_loss: 0.7155\n",
      "Epoch 56/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6572 - val_loss: 0.7123\n",
      "Epoch 57/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6542 - val_loss: 0.7091\n",
      "Epoch 58/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6513 - val_loss: 0.7059\n",
      "Epoch 59/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6484 - val_loss: 0.7030\n",
      "Epoch 60/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6456 - val_loss: 0.6999\n",
      "Epoch 61/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6429 - val_loss: 0.6968\n",
      "Epoch 62/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6401 - val_loss: 0.6938\n",
      "Epoch 63/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6374 - val_loss: 0.6908\n",
      "Epoch 64/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6348 - val_loss: 0.6880\n",
      "Epoch 65/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6322 - val_loss: 0.6852\n",
      "Epoch 66/100\n",
      "9288/9288 [==============================] - 0s 48us/sample - loss: 0.6297 - val_loss: 0.6823\n",
      "Epoch 67/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6271 - val_loss: 0.6796\n",
      "Epoch 68/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.6246 - val_loss: 0.6769\n",
      "Epoch 69/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6222 - val_loss: 0.6743\n",
      "Epoch 70/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6198 - val_loss: 0.6716\n",
      "Epoch 71/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6175 - val_loss: 0.6690\n",
      "Epoch 72/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6151 - val_loss: 0.6665\n",
      "Epoch 73/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.6128 - val_loss: 0.6640\n",
      "Epoch 74/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6106 - val_loss: 0.6615\n",
      "Epoch 75/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6083 - val_loss: 0.6591\n",
      "Epoch 76/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6062 - val_loss: 0.6567\n",
      "Epoch 77/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.6040 - val_loss: 0.6543\n",
      "Epoch 78/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.6019 - val_loss: 0.6519\n",
      "Epoch 79/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5998 - val_loss: 0.6497\n",
      "Epoch 80/100\n",
      "9288/9288 [==============================] - 0s 49us/sample - loss: 0.5978 - val_loss: 0.6474\n",
      "Epoch 81/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5957 - val_loss: 0.6451\n",
      "Epoch 82/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5937 - val_loss: 0.6429\n",
      "Epoch 83/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5917 - val_loss: 0.6408\n",
      "Epoch 84/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5898 - val_loss: 0.6385\n",
      "Epoch 85/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5879 - val_loss: 0.6363\n",
      "Epoch 86/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5860 - val_loss: 0.6342\n",
      "Epoch 87/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5841 - val_loss: 0.6320\n",
      "Epoch 88/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5823 - val_loss: 0.6299\n",
      "Epoch 89/100\n",
      "9288/9288 [==============================] - 0s 45us/sample - loss: 0.5804 - val_loss: 0.6278\n",
      "Epoch 90/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5787 - val_loss: 0.6259\n",
      "Epoch 91/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5769 - val_loss: 0.6239\n",
      "Epoch 92/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5751 - val_loss: 0.6218\n",
      "Epoch 93/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5734 - val_loss: 0.6198\n",
      "Epoch 94/100\n",
      "9288/9288 [==============================] - 0s 47us/sample - loss: 0.5717 - val_loss: 0.6179\n",
      "Epoch 95/100\n",
      "9288/9288 [==============================] - 0s 46us/sample - loss: 0.5701 - val_loss: 0.6160\n",
      "Epoch 96/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5684 - val_loss: 0.6141\n",
      "Epoch 97/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5668 - val_loss: 0.6122\n",
      "Epoch 98/100\n",
      "9288/9288 [==============================] - 0s 44us/sample - loss: 0.5652 - val_loss: 0.6104\n",
      "2322/2322 [==============================] - 0s 22us/sample - loss: 0.5933\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f0b78764160>, as the constructor either does not set or modifies parameter layer_size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1183e16337cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0;32m--> 736\u001b[0;31m                 **self.best_params_))\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[1;32m     81\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                (estimator, name))\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f0b78764160>, as the constructor either does not set or modifies parameter layer_size"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "param_distribution={\n",
    "    \"hidden_layers\":[1,2,3,4],\n",
    "    \"layer_size\":np.arange(1,100),\n",
    "    \"learning_rate\":reciprocal(1e-4,1e-2)\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search_cv=RandomizedSearchCV(sklearn_model,param_distribution,n_iter=10,n_jobs=1)\n",
    "\n",
    "random_search_cv.fit(x_train_s,y_train,epochs=100,validation_data=(x_valid_s,y_valid),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 3, 'layer_size': 40, 'learning_rate': 0.008848576453711657}\n",
      "-0.3673395312828406\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-491d980432ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)\n",
    "print(random_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e5cb771e7336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model=random_search_cv.best_estimator_.model\n",
    "model.evaluate(x_test_s,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
