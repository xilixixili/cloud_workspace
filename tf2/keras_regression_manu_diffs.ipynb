{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing=fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3870, 8) (3870,)\n",
      "(11610, 8) (11610,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all,x_test,y_train_all,y_test=train_test_split(housing.data,housing.target,random_state=7)\n",
    "x_train,x_valid,y_train,y_valid=train_test_split(x_train_all,y_train_all,random_state=11)\n",
    "\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "x_train_s=scaler.fit_transform(x_train)\n",
    "x_valid_s=scaler.fit_transform(x_valid)\n",
    "x_test_s=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.5, shape=(), dtype=float32)\n",
      "tf.Tensor(6.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric 使用\n",
    "\n",
    "metric=keras.metrics.MeanSquaredError()\n",
    "print(metric([5.],[2.]))\n",
    "print(metric([0.],[2.]))\n",
    "print(metric.result())\n",
    "\n",
    "metric.reset_states()\n",
    "metric([1.],[3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0 train mse: 7.4651025 0 train mse: 7.2201987.2897363train mse: 7.484408\t valid mse: 7.514695313928965\n",
      "Epoch 1 train mse: 7.5499444 7.477252 1 train mse: 7.4036956\t valid mse: 7.514695313928965\n",
      "Epoch 2 train mse: 7.3895802\t valid mse: 7.514695313928965se: 7.4180713\n",
      "Epoch 3 train mse: 7.57941753 train mse: 6.853963 3 train mse: 8.89248 7.9041557 7.731439\t valid mse: 7.514695313928965\n",
      "Epoch 4 train mse: 7.451952\t valid mse: 7.514695313928965se: 7.454432\n",
      "Epoch 5 train mse: 7.640652\t valid mse: 7.514695313928965\n",
      "Epoch 6 train mse: 7.44569647.45535\t valid mse: 7.514695313928965\n",
      "Epoch 7 train mse: 7.6528707\t valid mse: 7.514695313928965731382\n",
      "Epoch 8 train mse: 8.1690585 8 train mse: 8.206327 8 train mse: 7.800363\t valid mse: 7.514695313928965\n",
      "Epoch 9 train mse: 7.1418727 9 train mse: 7.0423584 9 train mse: 7.1578455\t valid mse: 7.514695313928965\n",
      "Epoch 10 train mse: 7.570007\t valid mse: 7.514695313928965\n",
      "Epoch 11 train mse: 7.2793765\t valid mse: 7.514695313928965\n",
      "Epoch 12 train mse: 7.5852847\t valid mse: 7.514695313928965815\n",
      "Epoch 13 train mse: 7.532934\t valid mse: 7.514695313928965rain mse: 7.612473\n",
      "Epoch 14 train mse: 7.3896123 14 train mse: 7.9828954 14 train mse: 7.663581 14 train mse: 7.4482403\t valid mse: 7.514695313928965\n",
      "Epoch 15 train mse: 7.517282\t valid mse: 7.514695313928965in mse: 7.3350606train mse: 7.5594006\n",
      "Epoch 16 train mse: 7.3491406 16 train mse: 7.558415\t valid mse: 7.514695313928965\n",
      "Epoch 17 train mse: 7.17877757.12702217 train mse: 7.1781864 17 train mse: 7.1296897\t valid mse: 7.514695313928965\n",
      "Epoch 18 train mse: 7.6263956 train mse: 7.4475183\t valid mse: 7.514695313928965\n",
      "Epoch 19 train mse: 7.50764\t valid mse: 7.514695313928965\n",
      "Epoch 20 train mse: 7.9512906 20 train mse: 7.83028\t valid mse: 7.514695313928965\n",
      "Epoch 21 train mse: 7.337339\t valid mse: 7.514695313928965\n",
      "Epoch 22 train mse: 7.2170734\t valid mse: 7.514695313928965\n",
      "Epoch 23 train mse: 7.4779234\t valid mse: 7.514695313928965\n",
      "Epoch 24 train mse: 7.4169254 24 train mse: 6.3638735 24 train mse: 7.409568 24 train mse: 7.4601355\t valid mse: 7.514695313928965\n",
      "Epoch 25 train mse: 7.323455\t valid mse: 7.514695313928965\n",
      "Epoch 26 train mse: 7.5651593 26 train mse: 7.5326295\t valid mse: 7.514695313928965\n",
      "Epoch 27 train mse: 7.782153627 train mse: 8.113894 27 train mse: 7.78739\t valid mse: 7.514695313928965\n",
      "Epoch 28 train mse: 7.6246414 28 train mse: 8.12759\t valid mse: 7.514695313928965\n",
      "Epoch 29 train mse: 8.155693\t valid mse: 7.514695313928965\n",
      "Epoch 30 train mse: 7.2804546 30 train mse: 7.216882 30 train mse: 7.2398086\t valid mse: 7.514695313928965\n",
      "Epoch 31 train mse: 7.85577235 8.765687 31 train mse: 8.204292 7.8329077\t valid mse: 7.514695313928965\n",
      "Epoch 32 train mse: 7.749702\t valid mse: 7.514695313928965ain mse: 7.7648883 32 train mse: 7.7224555\n",
      "Epoch 33 train mse: 7.5914874 33 train mse: 7.710878 33 train mse: 7.519216\t valid mse: 7.514695313928965\n",
      "Epoch 34 train mse: 7.51257235train mse: 7.5428376\t valid mse: 7.514695313928965\n",
      "Epoch 35 train mse: 7.0263214 35 train mse: 7.03771 35 train mse: 6.990905\t valid mse: 7.514695313928965\n",
      "Epoch 36 train mse: 7.3030343\t valid mse: 7.51469531392896586\n",
      "Epoch 37 train mse: 7.37720767.224832train mse: 7.504871 37 train mse: 7.4162993train mse: 7.385829\t valid mse: 7.514695313928965\n",
      "Epoch 38 train mse: 7.1909693 38 train mse: 7.1485434 38 train mse: 7.241769\t valid mse: 7.514695313928965\n",
      "Epoch 39 train mse: 7.5467814 39 train mse: 7.119825 39 train mse: 7.1184173\t valid mse: 7.514695313928965\n",
      "Epoch 40 train mse: 7.3735566\t valid mse: 7.514695313928965mse: 7.3247676 40 train mse: 7.26137\n",
      "Epoch 41 train mse: 7.6924076 41 train mse: 7.177007 41 train mse: 7.56602 41 train mse: 7.50343567.601674\t valid mse: 7.514695313928965\n",
      "Epoch 42 train mse: 7.460462\t valid mse: 7.514695313928965991\n",
      "Epoch 43 train mse: 7.3631577\t valid mse: 7.514695313928965\n",
      "Epoch 44 train mse: 7.2184784 44 train mse: 7.441478\t valid mse: 7.514695313928965\n",
      "Epoch 45 train mse: 7.2193846 45 train mse: 7.244445\t valid mse: 7.514695313928965\n",
      "Epoch 46 train mse: 7.3821454\t valid mse: 7.514695313928965se: 7.4113264\n",
      "Epoch 47 train mse: 7.224181647 train mse: 6.8542085 7.0539536 47 train mse: 7.09735\t valid mse: 7.514695313928965\n",
      "Epoch 48 train mse: 7.1772742 48 train mse: 7.2233896 7.0861516\t valid mse: 7.514695313928965\n",
      "Epoch 49 train mse: 7.4310424 49 train mse: 7.6367764\t valid mse: 7.514695313928965\n",
      "Epoch 50 train mse: 7.260742\t valid mse: 7.514695313928965rain mse: 7.043259 50 train mse: 7.122589train mse: 7.122496\n",
      "Epoch 51 train mse: 7.2942953 51 train mse: 7.680242 51 train mse: 6.8860583 51 train mse: 7.369583 51 train mse: 7.62018\t valid mse: 7.514695313928965\n",
      "Epoch 52 train mse: 7.5300965\t valid mse: 7.51469531392896594\n",
      "Epoch 53 train mse: 7.3965263\t valid mse: 7.514695313928965\n",
      "Epoch 54 train mse: 7.0822315\t valid mse: 7.514695313928965in mse: 7.1262116 54 train mse: 7.1455345\n",
      "Epoch 55 train mse: 7.15746455 train mse: 7.1057925train mse: 7.1768208\t valid mse: 7.514695313928965\n",
      "Epoch 56 train mse: 7.2578254 56 train mse: 7.3398185 56 train mse: 7.1235876 56 train mse: 7.252969\t valid mse: 7.514695313928965\n",
      "Epoch 57 train mse: 7.429816\t valid mse: 7.514695313928965rain mse: 7.3247285\n",
      "Epoch 58 train mse: 7.3522355 58 train mse: 6.8232846 58 train mse: 7.2720895\t valid mse: 7.514695313928965\n",
      "Epoch 59 train mse: 7.6159225\t valid mse: 7.514695313928965ain mse: 7.676603\n",
      "Epoch 60 train mse: 7.6029186\t valid mse: 7.514695313928965\n",
      "Epoch 61 train mse: 7.475352\t valid mse: 7.514695313928965 mse: 7.424775\n",
      "Epoch 62 train mse: 7.0272474 62 train mse: 7.007734\t valid mse: 7.514695313928965\n",
      "Epoch 63 train mse: 7.406649\t valid mse: 7.514695313928965\n",
      "Epoch 64 train mse: 7.3693266\t valid mse: 7.514695313928965\n",
      "Epoch 65 train mse: 7.5980725 65 train mse: 7.5514477.503175\t valid mse: 7.514695313928965\n",
      "Epoch 66 train mse: 7.4447985\t valid mse: 7.514695313928965\n",
      "Epoch 67 train mse: 7.32758\t valid mse: 7.514695313928965\n",
      "Epoch 68 train mse: 7.4866095 68 train mse: 7.04537157.4699435\t valid mse: 7.514695313928965\n",
      "Epoch 69 train mse: 7.3075976 69 train mse: 7.324621\t valid mse: 7.514695313928965\n",
      "Epoch 70 train mse: 7.693112457.699288 70 train mse: 7.557108470 train mse: 7.5228806\t valid mse: 7.514695313928965\n",
      "Epoch 71 train mse: 7.4956527 71 train mse: 7.2148767 71 train mse: 7.4448895\t valid mse: 7.514695313928965\n",
      "Epoch 72 train mse: 7.6187057 72 train mse: 7.5491395\t valid mse: 7.514695313928965\n",
      "Epoch 73 train mse: 7.3202085\t valid mse: 7.514695313928965\n",
      "Epoch 74 train mse: 7.427899\t valid mse: 7.514695313928965ain mse: 7.167643\n",
      "Epoch 75 train mse: 7.543641\t valid mse: 7.514695313928965 mse: 7.484488 75 train mse: 7.2506394\n",
      "Epoch 76 train mse: 7.249687476 train mse: 7.0464244\t valid mse: 7.514695313928965\n",
      "Epoch 77 train mse: 7.498198\t valid mse: 7.514695313928965\n",
      "Epoch 78 train mse: 7.5982356 78 train mse: 6.01029547.32244 78 train mse: 7.6854544 78 train mse: 7.6404977 78 train mse: 7.5951533\t valid mse: 7.514695313928965\n",
      "Epoch 79 train mse: 7.3082937 79 train mse: 7.372308 79 train mse: 7.524571 79 train mse: 7.470618\t valid mse: 7.514695313928965\n",
      "Epoch 80 train mse: 7.116937\t valid mse: 7.514695313928965\n",
      "Epoch 81 train mse: 7.4803347 81 train mse: 7.28367781 train mse: 7.259019 81 train mse: 7.4600797\t valid mse: 7.514695313928965\n",
      "Epoch 82 train mse: 7.3664923\t valid mse: 7.514695313928965ain mse: 7.3958282\n",
      "Epoch 83 train mse: 7.2979765 83 train mse: 7.4769235\t valid mse: 7.514695313928965\n",
      "Epoch 84 train mse: 7.325539\t valid mse: 7.514695313928965rain mse: 7.6712017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 train mse: 7.2216206 85 train mse: 7.289991 85 train mse: 7.1352916 85 train mse: 7.251398\t valid mse: 7.514695313928965\n",
      "Epoch 86 train mse: 8.0255045\t valid mse: 7.514695313928965\n",
      "Epoch 87 train mse: 7.5269096 87 train mse: 7.5768485\t valid mse: 7.514695313928965\n",
      "Epoch 88 train mse: 7.3606873\t valid mse: 7.514695313928965in mse: 7.418545 88 train mse: 7.409473\n",
      "Epoch 89 train mse: 7.2360385 89 train mse: 7.1223116\t valid mse: 7.514695313928965\n",
      "Epoch 90 train mse: 7.2731075train mse: 7.4172335 90 train mse: 7.2586503 90 train mse: 7.2838073\t valid mse: 7.514695313928965\n",
      "Epoch 91 train mse: 7.2240456train mse: 7.1541533\t valid mse: 7.514695313928965\n",
      "Epoch 92 train mse: 7.544037\t valid mse: 7.514695313928965\n",
      "Epoch 93 train mse: 7.3761706 93 train mse: 7.49835 93 train mse: 7.378527\t valid mse: 7.514695313928965\n",
      "Epoch 94 train mse: 7.2519293\t valid mse: 7.514695313928965\n",
      "Epoch 95 train mse: 7.3555603\t valid mse: 7.514695313928965\n",
      "Epoch 96 train mse: 7.3740196\t valid mse: 7.514695313928965\n",
      "Epoch 97 train mse: 7.4988313 97 train mse: 7.986077\t valid mse: 7.514695313928965\n",
      "Epoch 98 train mse: 7.4694576\t valid mse: 7.5146953139289653\n",
      "Epoch 99 train mse: 7.4723763\t valid mse: 7.514695313928965\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#    1.1 自动求导\n",
    "# 2. epoch 结束  验证集 metric\n",
    "\n",
    "epochs=100\n",
    "bs=32\n",
    "steps_per_epoch=len(x_train_s)//bs\n",
    "optimizer=keras.optimizers.SGD()\n",
    "metric=keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x,y,bs=32):\n",
    "    idx = np.random.randint(0,len(x),size=bs)\n",
    "    return x[idx],y[idx]\n",
    "\n",
    "model=keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_b,y_b=random_batch(x_train_s,y_train,bs)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred=model(x_b)\n",
    "            loss = tf. reduce_mean(keras.losses.mean_squared_error(y_b,y_pred))\n",
    "            metric(y_b,y_pred)\n",
    "        grads=tape.gradient(loss,model.variables)\n",
    "        grads_and_vars=zip(grads,model.variables)\n",
    "        print('\\rEpoch',epoch,'train mse:',metric.result().numpy(),end='')\n",
    "    y_v_pred=model(x_valid_s)\n",
    "    valid_loss=tf.reduce_mean(keras.losses.mean_squared_error(y_v_pred,y_valid))\n",
    "    print('\\t','valid mse:',valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_train_s,y_train,validation_data=(x_valid_s,y_valid),epochs=100,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7f6945ab9b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot_learning_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_s,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
