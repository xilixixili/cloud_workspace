{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=tf.keras.layers.Dense(100)\n",
    "layer=tf.keras.layers.Dense(100,input_shape=(None,5))\n",
    "layer(tf.zeros([4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_5/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
       " array([[ 6.87268823e-02,  1.10258609e-02, -1.25569880e-01,\n",
       "         -9.72458720e-03,  1.00663260e-01,  1.98606148e-01,\n",
       "         -9.88449752e-02,  2.10160628e-01, -1.41796112e-01,\n",
       "          9.93589908e-02,  8.18720609e-02,  1.40342966e-01,\n",
       "          1.76006064e-01, -1.31296873e-01, -3.58177871e-02,\n",
       "         -1.56302974e-01,  2.70455331e-02,  6.23021871e-02,\n",
       "         -5.58495522e-05,  2.27380857e-01,  1.42771319e-01,\n",
       "         -5.95643520e-02,  1.85462788e-01,  1.86793163e-01,\n",
       "          2.21075907e-01, -2.19942033e-01, -1.36262774e-01,\n",
       "          6.42888993e-02, -1.87474176e-01, -2.19961926e-01,\n",
       "          1.55799165e-01,  1.23210415e-01, -5.16342372e-02,\n",
       "          4.98384982e-02,  1.53157517e-01, -2.10559681e-01,\n",
       "         -1.68108150e-01,  1.73248067e-01,  1.27658144e-01,\n",
       "          2.01308534e-01, -8.85976404e-02,  6.54264838e-02,\n",
       "         -8.97586346e-02, -9.36295390e-02,  3.62076610e-02,\n",
       "          7.39082247e-02, -1.90812647e-01,  1.98306426e-01,\n",
       "         -1.10118851e-01,  1.68570980e-01,  4.26654518e-03,\n",
       "          1.59104303e-01, -2.38104090e-01,  1.84074193e-02,\n",
       "          1.36826560e-01,  1.09776214e-01, -6.24273866e-02,\n",
       "         -6.82967454e-02, -1.45686895e-01,  3.10822874e-02,\n",
       "          3.84811312e-02,  2.24194214e-01, -2.79624462e-02,\n",
       "          1.85871437e-01, -1.80922896e-01,  5.92935234e-02,\n",
       "         -1.41852126e-01,  5.36839217e-02,  1.86977938e-01,\n",
       "          1.83163628e-01,  4.95005399e-02, -2.20404983e-01,\n",
       "         -6.97311461e-02, -8.00410658e-02,  1.00792363e-01,\n",
       "          6.68859929e-02, -1.83394909e-01,  1.77292719e-01,\n",
       "         -3.00263911e-02, -1.13250330e-01, -1.13096163e-01,\n",
       "          4.34736907e-03, -2.18279839e-01,  1.69590548e-01,\n",
       "         -2.26593018e-03, -2.06891045e-01, -1.04430839e-01,\n",
       "          2.36738637e-01, -1.17363058e-01, -1.80916801e-01,\n",
       "          9.28566009e-02,  9.77571458e-02, -2.26848498e-01,\n",
       "         -2.00640976e-01,  1.51450768e-01,  8.29537958e-02,\n",
       "         -2.12211564e-01, -4.92113531e-02, -7.19611645e-02,\n",
       "         -1.71858102e-01],\n",
       "        [-1.78709403e-01,  1.07700869e-01, -1.95973486e-01,\n",
       "          9.14335996e-02,  1.68014899e-01,  1.97163031e-01,\n",
       "         -1.44164562e-01, -1.52433902e-01,  6.64807707e-02,\n",
       "         -1.34284258e-01,  1.00988001e-02,  2.23567054e-01,\n",
       "          1.91575661e-01, -1.18229538e-02,  1.88470647e-01,\n",
       "         -4.36228514e-02,  1.60629004e-02,  8.34564120e-02,\n",
       "          1.56924084e-01,  7.12765008e-02,  2.97740847e-02,\n",
       "         -2.25434437e-01, -2.18711615e-01, -5.31036258e-02,\n",
       "          1.29789695e-01, -1.14522703e-01, -1.81263089e-01,\n",
       "         -2.22661912e-01, -9.93528962e-02, -4.89988327e-02,\n",
       "          6.25392646e-02,  2.22777024e-01,  1.96452036e-01,\n",
       "          9.99008268e-02, -3.08964998e-02, -1.84118003e-02,\n",
       "          2.11185068e-02, -1.42884955e-01,  1.91246822e-01,\n",
       "          2.06024125e-01,  8.39558989e-02, -2.22744316e-01,\n",
       "          5.38380891e-02, -2.04302371e-01, -1.47339284e-01,\n",
       "         -2.43559927e-02, -3.60371470e-02, -9.72534418e-02,\n",
       "          6.64928705e-02,  1.53616831e-01, -2.13818774e-01,\n",
       "         -1.34953812e-01,  1.13657191e-01,  7.94363171e-02,\n",
       "         -1.07399151e-01,  9.04225558e-02, -2.17300862e-01,\n",
       "         -2.02205256e-01,  2.05305502e-01, -2.30921775e-01,\n",
       "          1.14574060e-01, -1.61247730e-01,  7.69553334e-02,\n",
       "         -2.16816828e-01,  1.94471925e-02,  1.14992410e-02,\n",
       "         -2.18873128e-01,  1.50876626e-01, -5.32588363e-03,\n",
       "          1.60885438e-01,  1.20338351e-02, -2.38126308e-01,\n",
       "         -6.49284720e-02, -2.07441151e-02, -1.45429969e-02,\n",
       "         -1.56070784e-01, -9.16597545e-02, -4.39606011e-02,\n",
       "         -1.63410157e-01, -1.89495087e-01,  1.26435086e-01,\n",
       "          7.85354227e-02,  2.20672384e-01, -1.97828263e-01,\n",
       "          4.94303256e-02, -1.10503614e-01,  8.85680467e-02,\n",
       "          1.68628380e-01,  1.41139701e-01, -1.38927877e-01,\n",
       "         -2.25514635e-01, -5.15423715e-02,  1.75628647e-01,\n",
       "         -3.29381526e-02, -1.67101771e-01, -1.02697060e-01,\n",
       "         -1.81393206e-01,  2.30812475e-01,  1.44106597e-02,\n",
       "         -1.67050019e-01],\n",
       "        [ 1.25421301e-01, -9.64063555e-02, -1.47333413e-01,\n",
       "         -5.42681664e-02, -7.87783861e-02,  8.79480392e-02,\n",
       "          2.37385973e-01,  1.22778267e-02, -2.06660926e-02,\n",
       "          1.41595200e-01, -1.76220924e-01, -9.31783915e-02,\n",
       "          6.34726435e-02,  4.33956832e-02,  1.98832646e-01,\n",
       "          7.42858499e-02, -1.23272836e-02,  1.86471790e-02,\n",
       "          1.10993996e-01,  1.89470127e-01, -8.17288458e-02,\n",
       "          1.40758649e-01,  1.26144871e-01,  7.70209879e-02,\n",
       "         -1.63304836e-01,  2.21532539e-01,  3.00136656e-02,\n",
       "         -1.85052842e-01,  5.01970500e-02,  1.47549078e-01,\n",
       "          1.74373105e-01,  6.35531098e-02,  1.93941638e-01,\n",
       "          2.27247432e-01,  1.42889842e-01, -1.84398443e-02,\n",
       "          2.04488620e-01,  1.17544994e-01, -1.92820400e-01,\n",
       "         -1.54165506e-01,  1.66241065e-01,  2.29763106e-01,\n",
       "         -8.69972706e-02, -1.30983114e-01, -1.26056582e-01,\n",
       "          6.32183254e-03, -1.11127064e-01,  5.11106998e-02,\n",
       "         -3.41288596e-02, -1.37288541e-01, -2.10816205e-01,\n",
       "         -1.54947788e-01,  2.13616714e-01,  5.98732084e-02,\n",
       "          1.68721721e-01, -1.06730908e-01,  1.12909809e-01,\n",
       "          7.74417669e-02,  8.56198221e-02, -1.16057292e-01,\n",
       "          3.65010053e-02,  5.97507805e-02,  1.83993891e-01,\n",
       "         -2.31873110e-01,  4.23322469e-02,  5.10149449e-02,\n",
       "         -7.86073506e-02, -1.40229464e-02, -1.31042451e-01,\n",
       "         -3.20913643e-02, -1.97565183e-01,  2.32426837e-01,\n",
       "          2.13630989e-01, -1.34628624e-01, -1.15215108e-01,\n",
       "         -2.03049496e-01, -2.22397521e-01,  1.52784333e-01,\n",
       "         -8.92161280e-02,  2.17745915e-01, -1.03429541e-01,\n",
       "         -1.77027255e-01,  3.84915620e-02,  1.03419498e-01,\n",
       "          1.64366052e-01, -1.59080178e-01,  5.38703054e-02,\n",
       "          1.51554480e-01, -2.35523269e-01, -1.55226320e-01,\n",
       "          1.92241356e-01, -1.71743497e-01, -8.06312263e-02,\n",
       "         -2.15925232e-01,  1.71845004e-01,  4.78956848e-02,\n",
       "         -6.27458096e-02, -1.58510774e-01, -1.91578582e-01,\n",
       "         -1.84608176e-01],\n",
       "        [-2.06313998e-01, -8.96403790e-02, -2.92721987e-02,\n",
       "         -5.11643291e-02,  4.11999077e-02, -1.19296715e-01,\n",
       "          2.08790556e-01,  1.50897354e-02, -2.05120444e-01,\n",
       "         -1.10667795e-02,  7.06918687e-02,  6.06503636e-02,\n",
       "          7.35838264e-02,  1.63937405e-01, -2.04244584e-01,\n",
       "          1.99673459e-01,  8.46670717e-02, -6.07647300e-02,\n",
       "          1.89731494e-01,  2.71396488e-02,  2.31068835e-01,\n",
       "          1.70039639e-01, -7.03656524e-02, -2.35219270e-01,\n",
       "         -2.16589019e-01, -2.29344666e-02,  8.98522139e-03,\n",
       "         -1.95775434e-01, -2.30576456e-01, -1.10776842e-01,\n",
       "         -1.86063036e-01,  6.53539151e-02,  1.97184831e-02,\n",
       "          3.68794352e-02, -2.32723504e-01, -7.44541585e-02,\n",
       "         -1.12662330e-01, -1.68320686e-02,  1.33594587e-01,\n",
       "         -2.31017977e-01,  2.62679905e-02,  6.52467161e-02,\n",
       "         -1.17054045e-01, -5.54523021e-02,  9.11749899e-03,\n",
       "         -2.03268915e-01,  1.63167715e-04, -1.45971298e-01,\n",
       "         -4.26695347e-02, -2.15429962e-02, -1.70895338e-01,\n",
       "         -1.46602392e-02,  1.38333544e-01,  1.52920261e-01,\n",
       "          1.29469320e-01,  8.41529667e-03, -2.44208425e-02,\n",
       "         -1.60572767e-01,  2.05897197e-01, -6.00006282e-02,\n",
       "          1.09061643e-01, -1.48016483e-01, -3.36271971e-02,\n",
       "          5.74077815e-02,  2.14028493e-01,  1.58023819e-01,\n",
       "         -1.17622316e-03, -3.15755159e-02,  1.77859515e-02,\n",
       "         -1.63725913e-01,  2.36673787e-01,  8.69830698e-02,\n",
       "         -4.48810905e-02, -5.15136421e-02,  1.03842899e-01,\n",
       "         -5.88695556e-02,  1.31547526e-01,  4.70826775e-02,\n",
       "          1.14590421e-01, -8.69756192e-02, -1.34620816e-01,\n",
       "         -2.29668334e-01, -6.46723360e-02, -3.88775021e-02,\n",
       "         -1.23776533e-01, -3.66635025e-02,  2.60625333e-02,\n",
       "          2.92860419e-02,  1.62578925e-01, -9.15804803e-02,\n",
       "          1.13205597e-01, -1.69565290e-01,  2.19865605e-01,\n",
       "         -4.62840199e-02, -1.43501461e-02, -1.17620096e-01,\n",
       "         -2.37610698e-01, -6.74597025e-02,  3.55723649e-02,\n",
       "         -1.12315536e-01],\n",
       "        [ 7.02038556e-02,  2.53734142e-02, -2.26701617e-01,\n",
       "         -1.46597818e-01,  7.76747614e-02, -1.81505829e-01,\n",
       "         -2.25930735e-01, -5.97244948e-02,  1.40084371e-01,\n",
       "         -1.70966238e-01,  2.06548735e-01,  2.30150953e-01,\n",
       "          1.74175605e-01, -3.28185856e-02,  2.18521491e-01,\n",
       "          8.44076425e-02, -2.73714960e-03,  8.99544805e-02,\n",
       "          7.91336149e-02, -9.75209624e-02, -1.41033426e-01,\n",
       "         -1.61029339e-01, -8.71578753e-02,  1.01254568e-01,\n",
       "          1.82082310e-01,  1.30401507e-01, -1.35902181e-01,\n",
       "          1.08043239e-01,  1.80218741e-01, -1.93587363e-01,\n",
       "         -1.70857206e-01,  1.79430410e-01, -1.76001042e-01,\n",
       "         -1.54621169e-01, -1.43862665e-01, -2.02222019e-01,\n",
       "         -1.20699883e-01,  1.26708314e-01, -1.27687335e-01,\n",
       "         -1.14409402e-01,  1.68498263e-01,  5.78650385e-02,\n",
       "         -9.40577835e-02, -1.25249505e-01,  5.62461764e-02,\n",
       "         -2.34270692e-02, -1.40857771e-01,  1.56291977e-01,\n",
       "          5.86345047e-02, -1.36035994e-01,  7.42851198e-03,\n",
       "         -1.13893598e-02, -2.68435031e-02,  9.43950862e-02,\n",
       "          1.07813045e-01, -1.25145793e-01,  1.36094138e-01,\n",
       "          1.00550935e-01, -9.52910036e-02,  5.88619560e-02,\n",
       "         -1.92248583e-01, -1.52960569e-01, -9.93475318e-02,\n",
       "         -5.58819771e-02, -4.90172356e-02, -1.48706153e-01,\n",
       "         -2.33648777e-01, -1.03835464e-02, -2.10700035e-02,\n",
       "          6.22513443e-02, -1.67621553e-01, -1.54650003e-01,\n",
       "         -1.79360658e-01, -2.05953121e-01,  1.26598924e-02,\n",
       "          7.28475302e-02,  1.43761620e-01,  3.46605927e-02,\n",
       "          1.10420123e-01, -2.31733814e-01, -1.24293230e-01,\n",
       "         -1.59723803e-01,  1.20661065e-01, -6.09948188e-02,\n",
       "          1.38643071e-01, -1.11322552e-01,  6.27770871e-02,\n",
       "         -2.31085286e-01,  1.90919504e-01,  2.19558313e-01,\n",
       "         -2.36494318e-01, -3.81051898e-02, -1.38062656e-01,\n",
       "          1.72977224e-01,  7.01849908e-02,  4.49356288e-02,\n",
       "          1.82912514e-01, -1.44306809e-01, -1.92378014e-01,\n",
       "         -1.46611601e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layer.variables\n",
    "# x*w+b\n",
    "layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dense in module tensorflow.python.keras.layers.core object:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing=fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3870, 8) (3870,)\n",
      "(11610, 8) (11610,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all,x_test,y_train_all,y_test=train_test_split(housing.data,housing.target,random_state=7)\n",
    "x_train,x_valid,y_train,y_valid=train_test_split(x_train_all,y_train_all,random_state=11)\n",
    "\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "x_train_s=scaler.fit_transform(x_train)\n",
    "x_valid_s=scaler.fit_transform(x_valid)\n",
    "x_test_s=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4.5417706e-05 6.7153489e-03 6.9314718e-01 5.0067153e+00 1.0000046e+01], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.nn.sotfplus: log(1+e^x)  Lambda\n",
    "customized_softplus=keras.layers.Lambda(lambda x :tf.nn.softplus(x))\n",
    "print(customized_softplus([-10.,-5.,0.,5.,10.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "customized_dense_layer (Cust (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "customized_dense_layer_1 (Cu (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# customized dense layer.\n",
    "class CustomizedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self,units,activation = None,**kwargs):\n",
    "        self.units=units\n",
    "        self.activation=keras.layers.Activation(activation)\n",
    "        super(CustomizedDenseLayer,self).__init__(**kwargs)\n",
    "    def build(self,input_shape):\n",
    "        \"\"\"\"\"\"\n",
    "        # x*w+b. input_shape:[None,a] w:[a,b] output_shape:[None,b]\n",
    "        self.kernel=self.add_weight(name='kernel',shape = (input_shape[1],self.units),initializer='uniform',trainable=True)\n",
    "        self.bias=self.add_weight(name='bias',shape=(self.units,),initializer='zeros',trainable=True)\n",
    "        super(CustomizedDenseLayer,self).build(input_shape)\n",
    "    def call(self,x):\n",
    "        \"\"\"\"\"\"\n",
    "        return self.activation(x@self.kernel+self.bias)\n",
    "        \n",
    "model=keras.models.Sequential([\n",
    "    CustomizedDenseLayer(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "    CustomizedDenseLayer(1),\n",
    "    customized_softplus,\n",
    "    #keras.layers.Dense(1,activation='softplus')\n",
    "    #keras.layers.Dense(1),keras.layers.Activation('softplus'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',optimizer=\"sgd\")\n",
    "\n",
    "callbacks=[keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 1.0912 - val_loss: 0.6386\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.5525 - val_loss: 0.5309\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4864 - val_loss: 0.4740\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4585 - val_loss: 0.4533\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4440 - val_loss: 0.4374\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4325 - val_loss: 0.4225\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4211 - val_loss: 0.4178\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4184 - val_loss: 0.4125\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4083 - val_loss: 0.4122\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4025 - val_loss: 0.4051\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3974 - val_loss: 0.4015\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3923 - val_loss: 0.4061\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3882 - val_loss: 0.4048\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3843 - val_loss: 0.4015\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3816 - val_loss: 0.4006\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3805 - val_loss: 0.3981\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train_s,y_train,validation_data=(x_valid_s,y_valid),epochs=100,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 21us/sample - loss: 0.4048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40481838089551114"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_s,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
