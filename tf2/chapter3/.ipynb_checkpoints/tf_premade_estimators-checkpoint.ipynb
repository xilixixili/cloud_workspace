{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.2\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# python 网页打开并保存\n",
    "#https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "#https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "#os.mkdir(\"./data\")\n",
    "from urllib import request\n",
    "url = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\" #网页地址\n",
    "wp = request.urlopen(url) #打开连接\n",
    "content = wp.read() #获取页面内容\n",
    "fp = open(\"./data/train.csv\",\"w+b\") #打开一个文本文件\n",
    "fp.write(content) #写入数据\n",
    "fp.close() #关闭文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "train_file=\"./data/train.csv\"\n",
    "eval_file=\"./data/eval.csv\"\n",
    "\n",
    "train_df=pd.read_csv(train_file)\n",
    "eval_df=pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train=train_df.pop('survived')\n",
    "y_eval=eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc3e6d9668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc3c60afd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind='barh')#barv 纵向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc3c1256d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc3c10df60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([train_df,y_train],axis=1).groupby('sex').survived.mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns=['sex','n_siblings_spouses','parch','class','deck','embark_town','alone']\n",
    "numeric_columns=['age','fare']\n",
    "\n",
    "feature_columns=[]\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab=train_df[categorical_column].unique()\n",
    "    print(categorical_column,vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(categorical_column,vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df,label_df,epochs=10,shuffle=True,bs=32):\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset=dataset.shuffle(10000)\n",
    "    dataset=dataset.repeat(epochs).batch(bs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': 0        male\n",
       " 1      female\n",
       " 2      female\n",
       " 3      female\n",
       " 4        male\n",
       "         ...  \n",
       " 622      male\n",
       " 623      male\n",
       " 624    female\n",
       " 625    female\n",
       " 626      male\n",
       " Name: sex, Length: 627, dtype: object,\n",
       " 'age': 0      22.0\n",
       " 1      38.0\n",
       " 2      26.0\n",
       " 3      35.0\n",
       " 4      28.0\n",
       "        ... \n",
       " 622    28.0\n",
       " 623    25.0\n",
       " 624    19.0\n",
       " 625    28.0\n",
       " 626    32.0\n",
       " Name: age, Length: 627, dtype: float64,\n",
       " 'n_siblings_spouses': 0      1\n",
       " 1      1\n",
       " 2      0\n",
       " 3      1\n",
       " 4      0\n",
       "       ..\n",
       " 622    0\n",
       " 623    0\n",
       " 624    0\n",
       " 625    1\n",
       " 626    0\n",
       " Name: n_siblings_spouses, Length: 627, dtype: int64,\n",
       " 'parch': 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 622    0\n",
       " 623    0\n",
       " 624    0\n",
       " 625    2\n",
       " 626    0\n",
       " Name: parch, Length: 627, dtype: int64,\n",
       " 'fare': 0       7.2500\n",
       " 1      71.2833\n",
       " 2       7.9250\n",
       " 3      53.1000\n",
       " 4       8.4583\n",
       "         ...   \n",
       " 622    10.5000\n",
       " 623     7.0500\n",
       " 624    30.0000\n",
       " 625    23.4500\n",
       " 626     7.7500\n",
       " Name: fare, Length: 627, dtype: float64,\n",
       " 'class': 0       Third\n",
       " 1       First\n",
       " 2       Third\n",
       " 3       First\n",
       " 4       Third\n",
       "         ...  \n",
       " 622    Second\n",
       " 623     Third\n",
       " 624     First\n",
       " 625     Third\n",
       " 626     Third\n",
       " Name: class, Length: 627, dtype: object,\n",
       " 'deck': 0      unknown\n",
       " 1            C\n",
       " 2      unknown\n",
       " 3            C\n",
       " 4      unknown\n",
       "         ...   \n",
       " 622    unknown\n",
       " 623    unknown\n",
       " 624          B\n",
       " 625    unknown\n",
       " 626    unknown\n",
       " Name: deck, Length: 627, dtype: object,\n",
       " 'embark_town': 0      Southampton\n",
       " 1        Cherbourg\n",
       " 2      Southampton\n",
       " 3      Southampton\n",
       " 4       Queenstown\n",
       "           ...     \n",
       " 622    Southampton\n",
       " 623    Southampton\n",
       " 624    Southampton\n",
       " 625    Southampton\n",
       " 626     Queenstown\n",
       " Name: embark_town, Length: 627, dtype: object,\n",
       " 'alone': 0      n\n",
       " 1      n\n",
       " 2      y\n",
       " 3      n\n",
       " 4      y\n",
       "       ..\n",
       " 622    y\n",
       " 623    y\n",
       " 624    y\n",
       " 625    n\n",
       " 626    y\n",
       " Name: alone, Length: 627, dtype: object}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=make_dataset(train_df,y_train,bs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([28.,  2., 18., 28., 17.])>, 'n_siblings_spouses': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 4, 0, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 0, 0], dtype=int32)>, 'fare': <tf.Tensor: shape=(5,), dtype=float64, numpy=array([30.5   , 39.6875,  8.3   ,  7.775 ,  8.6625])>, 'class': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'First', b'Third', b'Third', b'Third', b'Third'], dtype=object)>, 'deck': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'C', b'unknown', b'unknown', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton'], dtype=object)>, 'alone': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([1 0 0 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[35.]\n",
      " [28.]\n",
      " [28.]\n",
      " [28.]\n",
      " [28.]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /root/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /root/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "\n",
    "for x,y in train_dataset.take(1):\n",
    "    age_column=feature_columns[7]\n",
    "    gender_column=feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[34.      0.      1.      0.      1.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  26.55    0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.8958  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [44.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.925   0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [33.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.775   0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [28.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  69.55    0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   0.      1.      0.      0.      0.      1.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "\n",
    "for x,y in train_dataset.take(1):\n",
    "    age_column=feature_columns[7]\n",
    "    gender_column=feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7797 - val_loss: 0.5360 - val_accuracy: 0.7266\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7391 - val_loss: 0.4961 - val_accuracy: 0.7539\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7672 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7609 - val_loss: 0.4914 - val_accuracy: 0.7539\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7719 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7547 - val_loss: 0.5919 - val_accuracy: 0.7227\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7219 - val_loss: 0.5158 - val_accuracy: 0.7422\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7688 - val_loss: 0.6056 - val_accuracy: 0.7070\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7594 - val_loss: 0.5112 - val_accuracy: 0.7461\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7484 - val_loss: 0.5284 - val_accuracy: 0.7422\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7547 - val_loss: 0.5374 - val_accuracy: 0.7305\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7641 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7844 - val_loss: 0.5695 - val_accuracy: 0.7227\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7891 - val_loss: 0.6423 - val_accuracy: 0.7109\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7625 - val_loss: 0.4930 - val_accuracy: 0.7617\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7656 - val_loss: 0.6364 - val_accuracy: 0.7148\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7703 - val_loss: 0.5242 - val_accuracy: 0.7461\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7828 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7688 - val_loss: 0.5331 - val_accuracy: 0.7266\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7906 - val_loss: 0.5011 - val_accuracy: 0.7422\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7437 - val_loss: 0.5679 - val_accuracy: 0.7109\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7781 - val_loss: 0.5073 - val_accuracy: 0.7578\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7734 - val_loss: 0.5514 - val_accuracy: 0.7305\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7734 - val_loss: 0.5079 - val_accuracy: 0.7578\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7516 - val_loss: 0.5220 - val_accuracy: 0.7461\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7484 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7719 - val_loss: 0.5249 - val_accuracy: 0.7422\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7672 - val_loss: 0.5539 - val_accuracy: 0.7109\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7797 - val_loss: 0.4879 - val_accuracy: 0.7773\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7609 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7500 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7937 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7734 - val_loss: 0.5163 - val_accuracy: 0.7539\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7766 - val_loss: 0.5232 - val_accuracy: 0.7461\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7781 - val_loss: 0.5080 - val_accuracy: 0.7422\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7766 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7812 - val_loss: 0.5445 - val_accuracy: 0.7266\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7594 - val_loss: 0.5055 - val_accuracy: 0.7461\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7797 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7656 - val_loss: 0.5947 - val_accuracy: 0.6719\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7750 - val_loss: 0.6186 - val_accuracy: 0.6953\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7703 - val_loss: 0.4805 - val_accuracy: 0.7812\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7766 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7766 - val_loss: 0.5907 - val_accuracy: 0.6953\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7734 - val_loss: 0.6172 - val_accuracy: 0.6523\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7906 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7672 - val_loss: 0.5434 - val_accuracy: 0.7148\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7234 - val_loss: 0.4950 - val_accuracy: 0.7617\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7563 - val_loss: 0.5066 - val_accuracy: 0.7461\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7672 - val_loss: 0.5198 - val_accuracy: 0.7422\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7906 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7844 - val_loss: 0.4859 - val_accuracy: 0.7734\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7953 - val_loss: 0.6458 - val_accuracy: 0.6523\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7516 - val_loss: 0.5581 - val_accuracy: 0.7266\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7734 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7766 - val_loss: 0.4838 - val_accuracy: 0.7578\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7766 - val_loss: 0.4934 - val_accuracy: 0.7617\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7828 - val_loss: 0.5908 - val_accuracy: 0.7148\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7641 - val_loss: 0.4870 - val_accuracy: 0.7617\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7516 - val_loss: 0.4900 - val_accuracy: 0.7617\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7828 - val_loss: 0.4971 - val_accuracy: 0.7578\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7953 - val_loss: 0.4816 - val_accuracy: 0.7656\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7547 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7734 - val_loss: 0.5035 - val_accuracy: 0.7617\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7797 - val_loss: 0.4917 - val_accuracy: 0.7344\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7891 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7953 - val_loss: 0.4974 - val_accuracy: 0.7773\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7766 - val_loss: 0.5303 - val_accuracy: 0.7305\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7797 - val_loss: 0.5127 - val_accuracy: 0.7461\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7688 - val_loss: 0.4910 - val_accuracy: 0.7617\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7844 - val_loss: 0.5141 - val_accuracy: 0.7539\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7797 - val_loss: 0.4897 - val_accuracy: 0.7773\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7641 - val_loss: 0.4905 - val_accuracy: 0.7539\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7844 - val_loss: 0.5054 - val_accuracy: 0.7539\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7828 - val_loss: 0.5213 - val_accuracy: 0.7383\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7937 - val_loss: 0.4920 - val_accuracy: 0.7695\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7797 - val_loss: 0.4973 - val_accuracy: 0.7695\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8016 - val_loss: 0.4857 - val_accuracy: 0.7539\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7406 - val_loss: 0.4946 - val_accuracy: 0.7539\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7766 - val_loss: 0.4881 - val_accuracy: 0.7617\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7844 - val_loss: 0.5024 - val_accuracy: 0.7539\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8031 - val_loss: 0.4980 - val_accuracy: 0.7617\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7937 - val_loss: 0.4904 - val_accuracy: 0.7578\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7891 - val_loss: 0.5094 - val_accuracy: 0.7578\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8016 - val_loss: 0.6866 - val_accuracy: 0.7031\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7922 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7641 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7688 - val_loss: 0.5143 - val_accuracy: 0.7617\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7875 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7578 - val_loss: 0.5301 - val_accuracy: 0.7148\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7828 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7750 - val_loss: 0.4760 - val_accuracy: 0.7734\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8047 - val_loss: 0.5076 - val_accuracy: 0.7852\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7578 - val_loss: 0.4941 - val_accuracy: 0.7773\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8000 - val_loss: 0.5084 - val_accuracy: 0.7695\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7742 - val_loss: 0.5810 - val_accuracy: 0.7188\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dca612f8a366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                  \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                  epochs=100)\n\u001b[0m",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;31m# End of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "#1. model.fit\n",
    "#2. model->estimator->train\n",
    "\n",
    "train_dataset=make_dataset(train_df,y_train,epochs=100)\n",
    "eval_dataset=make_dataset(eval_df,y_eval,epochs=1,shuffle=False)\n",
    "history=model.fit(train_dataset,\n",
    "                 validation_data=eval_dataset,\n",
    "                 steps_per_epoch=20,\n",
    "                 validation_steps=8,\n",
    "                 epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpiw3c4e9o\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpiw3c4e9o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-333ef9a89b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#2.return a. (featrues,labels) b.dataset->(feature,label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1162\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1192\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1194\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    636\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m       if all([\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    419\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 421\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    422\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environment/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator=keras.estimator.model_to_estimator(model)\n",
    "#1. function\n",
    "#2.return a. (featrues,labels) b.dataset->(feature,label)\n",
    "\n",
    "estimator.train(input_fn= lambda: make_dataset(train_df,y_train,epochs=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
